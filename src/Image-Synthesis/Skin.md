## Outline
N/A| [FaceWorks - NVIDIA](https://github.com/NVIDIAGameWorks/FaceWorks/blob/master/doc/slides/FaceWorks-Overview-GTC14.pdf) | UE4 | [Disney SSS - Unity3D](https://github.com/Unity-Technologies/Graphics/blob/master/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.hlsl) 
:-: | :-: | :-: | :-:  
Subsurface Scattering | Pre-Integrated | [Separable SSS](https://github.com/EpicGames/UnrealEngine/blob/release/Engine/Shaders/Private/SeparableSSS.ush) |  TODO
Transmitted Light | Deep Scatter | TODO |  TODO

### Diffusion Profile  

Currently, all real time approaches are based on the diffusion profile(**14.4.2 Rendering with Diffusion Profile** of \[dEon 2007\]) rather than the [BSSRDF](https://www.pbr-book.org/3ed-2018/Color_and_Radiometry/Surface_Reflection#TheBSSRDF).  

By using the diffusion profile, the subsurface scattering, which was described by the BSSRDF, is simplified by scattering the **amount** of light (technically, the **irradiance E**) of each location to the vicinal locations according to the weights indicated by the diffusion profile. Note that the **outgoing** irradiance E can also be called **radiant exitance M** and might be called **radiosity B** in the last century. Evidently, an equivalent gather operation can be used to replace the scatter operation, and the total **radiant exitance** can be considered as $\displaystyle \operatorname{M}(p_o) = \int_{S_{p_i}} \operatorname{R}(p_o, p_i) \cdot \operatorname{E}(p_i) \, dp_i$ where the $\displaystyle \operatorname{R}(p_o, p_i)$ is the diffusion profile. And, currently, all real time approaches assume that the material is homogeneous. This means that the 2D diffusion profile $\displaystyle \operatorname{R}(p_o, p_i)$ is radially symmetric, and can be reduced to the 1D diffusion profile $\displaystyle \operatorname{R}(\operatorname{distance}(p_o, p_i))$. And for the diffuse term, the outgoing radiance is assumed to be the same in all directions. Thus, the diffuse term can be simplified to $\displaystyle \operatorname{L}_o(p_o) = \frac{\operatorname{M}(p_o)}{\pi} = \frac{1}{\pi} \cdot \int_{S_{p_i}} \operatorname{R}(\operatorname{distance}(p_o, p_i)) \cdot \operatorname{E}(p_i) \, dp_i$.  

However, things are far from simple. Although the proposals based on the diffusion profile are much simpler than the BSSRDF, a general 2D convolution is still too expensive for real time rendering. Actually, according to \[dEon 2007\], if the width (technically, the range of the significant contribution domain) of the diffusion profile is about 16 mm, and the width of pixel is about 0.25 mm, we would need 4096(64 x 64) samples per pixel in the shader. Thus, we have to propose more efficient approaches to settle this problem.

## 1\. FaceWorks - NVIDIA

### 1-1\. Pre-Integrated
The **Subsurface Scattering** of FaceWorks is based on the **Pre-Integrated** \[Penner 2011\].  

In real time rendering, the light is assumed to be the punctual light rather than the area light. The [Delta Distribution](https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/Sampling_Light_Sources#LightswithSingularities) is applied, and the reflectance equation is simplified to $\displaystyle \operatorname{L}_o(p, \omega_o) = \int_\Omega \operatorname{BRDF}(p, \omega_o, \omega_i) \cdot \operatorname{L_i}(p, \omega_i) \cdot |\cos(\theta_i)| \, d\omega_i = \operatorname{BRDF}(p_i, \omega_o, \omega_i) \otimes \operatorname{E_{L}}(p) \otimes |\cos(\theta_i)|$ where the $\displaystyle \operatorname{E_{L}}(p)$ is the irradiance perpendicular to the light direction. And since the diffuse BRDF equals $\displaystyle \frac{c_{diffuse}}{\pi}$ which is irrelevant to the the $\displaystyle w_o$ and the $\displaystyle w_i$, the reflectance equation can be simplified further to $\displaystyle \operatorname{L}_o(p) = \frac{\operatorname{c_{diffuse}}(p)}{\pi} \otimes \operatorname{E_{L}}(p) \otimes |\cos(\theta_i)|$. Thus, the irradiance E  can be calculated as $\displaystyle \operatorname{E}(p) = \int_\Omega \operatorname{L}_o(p, \omega_o) \, d\omega_o  = \operatorname{L}_o(p) \cdot \int_\Omega 1 \, d\omega_o = \operatorname{L}_o(p) \cdot \pi = \operatorname{c_{diffuse}}(p) \otimes \operatorname{E_{L}}(p) \otimes |\cos(\theta_i)|$, and the diffuse term is simplified to $\displaystyle \operatorname{L}_o(p_o) = \frac{\operatorname{M}(p_o)}{\pi} = \frac{1}{\pi} \cdot \int_{S_{p_i}} \operatorname{R}(\operatorname{distance}(p_o, p_i)) \cdot \operatorname{c_{diffuse}}(p_i) \cdot \operatorname{E_{L}}(p_i) \cdot |\cos(\theta_i)| \, dp_i$.  

The main idea of \[Penner 2011\] is that the $\displaystyle \operatorname{c_{diffuse}}(p_i) \cdot \operatorname{E}(p_i)$ is assumed to be the constant $\displaystyle \operatorname{c_{diffuse}}(p_o) \cdot \operatorname{E}(p_o)$ for all vicinal locations. And thus, the $\displaystyle \operatorname{R}(\operatorname{distance}(p_o, p_i)) \cdot |\cos(\theta_i)|$ part of the diffuse term can be **pre-integrated** and stored in a LUT(Look Up Texture) which is called the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$. The $\displaystyle \theta$ is merely the traditional $\displaystyle \operatorname{dot}(N,L)$, and the $\displaystyle \frac{1}{r}$, which is called **curvature** by \[Penner 2011\], can be calculated on-the-fly as $\displaystyle \frac{1}{r} = \frac{\operatorname{ddx}(N)}{\operatorname{ddx}(P)}$. However, the on-the-fly method may be inaccurate since FaceWorks chooses to precompute the curvature instead. In conclusion, the diffuse term can be calculated as $\displaystyle \operatorname{D}(\operatorname{dot}(N,L), \frac{\operatorname{ddx}(N)}{\operatorname{ddx}(P)}) \otimes \frac{\operatorname{c_{diffuse}}(p)}{\pi} \otimes \operatorname{E_{L}}(p)$.
 
Usually, the diffusion profile is normalized which indicates the energy conservation. This means that $\displaystyle \int_0^\infin R(r) \, dr =1$. However, according to \[Penner 2011\], $\displaystyle \operatorname{D}(\theta, \frac{1}{r}) = \frac{\int_{-\pi}^{\pi} | \cos (\theta + x) | \cdot R(2r\sin(\frac{x}{2})) \,dx}{\int_{-\pi}^{\pi} R(2r\sin(\frac{y}{2})) \,dy}$ where denominator is added to make sure the diffusion profile is normalized.

In the GPU Pro 2, the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$ is calculated by **integrateDiffuseScatteringOnRing**. And there are some points to note.  
1. \[Penner 2011\] merely follows \[dEon 2007\] and the diffusion profile is approximated by the Gaussians (the **Scatter** in the code). However, the motivation of \[dEon 2007\] is that the [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) is a [separable filter](https://en.wikipedia.org/wiki/Separable_filter), and thus the general 2D convolution can be replaced by 1D convolutions to improve the performance. In my opinion, it is acceptable to perform a general 2D convolution even by using the exact accurate diffusion profile, since the approach proposed by \[Penner 2011\] **pre-integrates** the convolution, and the efficiency doesn't matter too much for offline precomputing.  
2. The **pre-integral** is performed on a ring rather than on a sphere. This is reasonable since it is assumed that the diffusion profile is radially symmetric.  
3. In the FaceWorks, according to the **numerical quadrature**, the funtion value $\operatorname{f}(x)$ is multiplied by the difference of the domain $\displaystyle \operatorname{\Delta}x$ (the **scale** in the code).  
However, in the GPU Pro 2, there is no such code like **scale** since the $\displaystyle \operatorname{\Delta}x$ appears in both numerator and denominator, and the it is not necessary to multiply $\displaystyle \operatorname{f}(x)$ by $\displaystyle \operatorname{\Delta}x$.  

In the FaceWorks, the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$ is calculated by **GFSDK_FaceWorks_GenerateCurvatureLUT**. However, there is some subtle modification.  
1. The $\displaystyle 2r\sin(\frac{x}{2})$ is replaced by the $\displaystyle rx$ (the **delta** in the code). Technically, the $\displaystyle 2r\sin(\frac{x}{2})$ is more correct since the diffusion profile describes the light absorption inside the medium rather than over the surface. Perhaps the $\displaystyle 2r\sin(\frac{x}{2})$ and the $\displaystyle rx$ are close when the $\displaystyle x$ is small.  
2. The denominator $\displaystyle \int_{-\pi}^{\pi} R(2r\sin(\frac{y}{2})) \,dy$ is omitted perhaps due to the fact that the diffusion profile has been normalized. Actually, I try to calculate the denominator by myself, and I find the denominator is really close to one.  
3. In the GPU Pro 2, three normals should be used for different RGB components and the LUT should be sampled three times according to three different $\displaystyle \theta$s. Perhaps this method is not efficient and the FaceWorks detaches the $\displaystyle \operatorname{dot}(N,L)$, which denotes the part of the integral where x is close to zero and the diffuse profile is close to one, from the total integral $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$. Evidently, the remaining part of the integral is relatively small, and thus FaceWorks maps the remaining part of the integral from [-0.25, 0.25] to [0, 1] to fully use the precision of the texture (the **rgbAdjust** in the code). The **GFSDK_FaceWorks_EvaluateSSSDirectLight** is used to calculate the diffuse term. The LUT is only sampled once and three normals are used to calculate the $\displaystyle \operatorname{dot}(N,L)$ which is detached from the total integral. 


### 1-2\. Deep Scatter
The **Transmitted Light** of FaceWorks is based on the **16.3 Simulating Absorption Using Depth Maps** of \[Green 2004\].  

TODO

## 2\. Separable SSS - UE4  

### 2-1\. Separable SSS
The **Subsurface Scattering** of UE4 is based on the **Separable SSS** \[Jimenez 2012\].  

The approach of \[dEon 2007\] is to approximate the diffusion profile by the weighted sum of 6 Gaussians, and thus the general 2D convolution can be replaced by 12(2 x 6) 1D convolutions since the [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) is a [separable filter](https://en.wikipedia.org/wiki/Separable_filter). However, the approach proposed by \[dEon 2007\] is applied in texture space which is too weird according to the convention of the real time rendering. And the screen space approach is proposed by \[Jimenez 2009\] and \[Jimenez 2010\]. However, the approach proposed by \[Jimenez 2010\] still needs 12(2 x 6) passes to perform the 12(2 x 6) 1D convolutions. Evidently, this is still too expensive for real time rendering. And thus, the 2 passes approach is proposed by \[Jimenez 2012\].    

According to the **numerical quadrature**, the funtion value sampled from the irradiance texture should be multiplied by the difference of the domain $\displaystyle \operatorname{\Delta} p_i$. \[dEon 2007\] proposed the **stretch texture**, where the difference of the world position is stored, to described the $\displaystyle \operatorname{\Delta} p_i$. Definitely, the screen space depth can be used to calculate the world position and thus the $\displaystyle \operatorname{\Delta} p_i$ can be obtained. However, the **stretch factor** proposed by \[Jimenez 2010\] is not proportional to the difference of the world position, and in my opinion, is empirical. And \[Mikkelsen 2010\] proposed a more reasonable approach to calculate the **kernel** size which is based on the mathematical derivation. Note that in image processing, the **filter** is a (continuous) function which is approximated by a discrete and finite **kernel**.  

The the demo source code of \[Jimenez 2012\] is provided by \[Jimenez 2015\]. Perhaps you can not believe it but it is really the truth. **The demo source code provided by \[Jimenez 2015\]  has nothing to do with \[Jimenez 2015\]**. This is really arcane, and I do spend some time to realize this fact.   

The main idea of \[Jimenez 2012\] is that in real time rendering, the non-separable diffusion profile is represented by the discretized kernel where the SVD can be applied, and the SVD indicates that the diffusion profile kernel can be approximated by a separable kernel $\displaystyle \operatorname{M}(x_o, y_o) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{S}(\Delta x)) \cdot \operatorname{S^T}(\Delta y)$, and $\displaystyle \operatorname{S}(\Delta x) = \operatorname{P}(\frac{\Delta x*w}{0.001 + f})*t + \operatorname{\delta}(\Delta x)*(1-t)$ where P denotes the 1D diffusion profile, $\displaystyle \operatorname{\delta}(\Delta x)$ denotes the [delta function](https://en.wikipedia.org/wiki/Dirac_delta_function) such that $\displaystyle \operatorname{\delta}(0) = 1$, t denotes the **strength**, w denotes the **width**, and f denotes the **falloff**.  

The $\displaystyle \operatorname{S}(\Delta x)$ is calculated by the **calculateKernel** in the demo source code provided by \[Jimenez 2015\] and the **ComputeMirroredSSSKernel** in the UE4. And there are some points to note.  
1. The **strength**, which is the **SubsurfaceColor** in the UE4, is to lerp between the SSS diffuse term $\displaystyle \operatorname{P}(\frac{\Delta x*w}{0.001 + f})$ and the conventional diffuse term $\displaystyle \operatorname{\delta}(\Delta x)$. Evidently, when the **strength** equals zero, since $\displaystyle \operatorname{S}(\Delta x) = \displaystyle \operatorname{\delta}(\Delta x)$ and $\displaystyle \operatorname{\delta}(0) = 1$, the formula is reduced to the conventional diffuse term $\displaystyle \operatorname{M}(x_o, y_o) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{S}(\Delta x)) \cdot \operatorname{S^T}(\Delta y) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{\delta}(\Delta x)) \cdot \operatorname{\delta}(\Delta y) = \operatorname{E}(x_o, y_o)$. The default of the **strength** in the demo source code is (0.48, 0.41, 0.28).  
2. According to \[dEon 2007\], the width of the diffusion profile is about 16 mm. The **falloff**, which is the **FalloffColor** in the UE4, is to make the diffusion profile narrower, and thus the width of the diffusion profile in the demo source code is reduced to 6(3x2) mm (the **RANGE** in the **calculateKernel** in the code). The default of the **falloff** in the demo source code is (1.0, 0.37, 0.3).  
3. According to the **numerical quadrature**, the function value sampled from the irradiance texture should be multiplied by the difference of the domain the $\displaystyle \operatorname{\Delta} x$ and the $\displaystyle \operatorname{\Delta} y$ (the **area** in the **calculateKernel** in the code). And the demo source code demonstrates that the deviations of the locations of the samples in world space (in mm) is fixed and stored in the **w** component of the **kernel** member of the **SeparableSSS** class. Thus, the mere purpose of the **SSSSBlurPS** in the shader code is to transform the deviations from world space to texture space. Assuming that the deviations are placed at the origin of the Y axis, the transformation can be calculated as $\displaystyle \text{TextureSpace} = \frac{0.001 \times \text{WorldSpaceUnitPerMeter}}{\tan(\text{FOVY} \times 0.5) \times 2} \times \text{WorldSpaceInMM}$ where the 0.001 is to transform from mm to m, the $\displaystyle \frac{1}{\tan(\text{FOVY} \times 0.5)}$ is the second row and the second column of the projection matrix, and the 2 is to transform from NDC to texture space. However, since the width of the diffusion profile is fixed at 6(3x2) mm as we have mentioned, the **sssWidth**, which is **ScatterRadius** in the UE4, is impossible to be considered as the **width** of the diffusion profile. And since the shader code of the demo source code demonstrates that the transformation is calculated as $\displaystyle \text{TextureSpace} = \frac{\text{sssWidth}}{\tan(\text{FOVY} \times 0.5) \times 3} \times \text{WorldSpaceInMM}$, by comparing these two formulas, a hypothesis can be proposed that $\displaystyle \text{WorldSpaceUnitPerMeter} = \frac{0.001 \times 3 \times \text{sssWIdth}}{2}$. The default of the **sssWidth** in the demo source code is 0.012, and thus the hypothesis implies that the **WorldSpaceUnitPerMeter** of the demo is 8. Actually, I check the vertex data of the head mesh in the demo, and fortunately, I find the vertex data is consistent with this result.  
4. The **SSSS_STREGTH_SOURCE** in the shader code has nothing to do with the **strength** in the paper at all. In the demo source code, the **SSSS_STREGTH_SOURCE** is the alpha channel of the albedo texture, and is used to skip the pixels which represent the eyebrow rather than the skin.  
    
### 2-2\. Transmittance

TODO

## 3\. Disney SSS - Unity3D  
TODO

## References

\[dEon 2007\] [Eugene dEon, David Luebke. "Advanced Techniques for Realistic Real-Time Skin Rendering." GPU Gem 3.](https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-14-advanced-techniques-realistic-real-time-skin)  
\[Penner 2011\] Eric Penner, George Borshukov. "Pre-Integrated Skin Shading." GPU Pro 2.  
\[Penner 2011\] [Eric Penner. "Pre-Integrated Skin Shading." SIGGRAPH 2011.](http://advances.realtimerendering.com/s2011/)  
\[Green 2004\] [Simon Green. "Chapter 16. Real-Time Approximations to Subsurface Scattering." GPU Gems 1.](https://developer.nvidia.com/gpugems/gpugems/part-iii-materials/chapter-16-real-time-approximations-subsurface-scattering)  
\[Jimenez 2009\] [Jorge Jimenez, Veronica Sundstedt, Diego Gutierrez. "Screen-Space Perceptual Rendering of Human Skin." ACM TAP 2009.](https://www.iryoku.com/sssss/)  
\[Jimenez 2010\] Jorge Jimenez, Diego Gutierrez. "Screen-Space Subsurface Scattering." GPU Pro 1.  
\[Mikkelsen 2010\] [Morten Mikkelsen. "Skin Rendering by Pseudoâ€“Separable Cross Bilateral Filtering." Naughty Dog.](https://mmikk.github.io/papers3d/cbf_skin.pdf)  
\[Jimenez 2012\] [Jorge Jimenez, Adrian Jarabo, Diego Gutierrez. "Separable Subsurface Scattering." Technical Report 2012.](https://graphics.unizar.es/publications.html#year_2012)   
\[Jimenez 2012\] [Jorge Jimenez, Adrian Jarabo, Diego Gutierrez, Etienne Danvoye, Javier von der Pahlen. "Separable Subsurface Scattering and Photorealistic Eyes Rendering." SIGGRAPH 2012.](http://advances.realtimerendering.com/s2012/index.html)  
\[Jimenez 2015\] [Jorge Jimenez, Karoly Zsolnai, Adrian Jarabo1, Christian Freude, Thomas Auzinger, Xian-Chun Wu, Javier von der Pahlen, Michael Wimmer, Diego Gutierrez. "Separable Subsurface Scattering." EGSR 2015.](http://www.iryoku.com/separable-sss/)  
