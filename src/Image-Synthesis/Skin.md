N/A | [NVIDIA FaceWorks](https://github.com/NVIDIAGameWorks/FaceWorks/blob/master/doc/slides/FaceWorks-Overview-GTC14.pdf) | [Demo Source Code of Jimenez 2015]((http://www.iryoku.com/separable-sss/)) | UE4 | Unity3D  
:-: | :-: | :-: | :-: | :-: 
Diffuse Reflectance Term | Preintegrated | [Separable SSS](https://graphics.unizar.es/publications.html#year_2012) | [Preintegrated](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush) + [Disney Diffuse](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush) + [Separable SSS](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Source/Runtime/Engine/Private/Rendering/SeparableSSS.cpp) + [Disney SSS](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Source/Runtime/Engine/Private/Rendering/BurleyNormalizedSSS.cpp) | [Disney Diffuse](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/Lit/Lit.hlsl) + [Disney SSS](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.compute)  
Diffuse Transmittance Term | Deep Scatter | [Analytically-Integrated Translucency](http://www.iryoku.com/translucency/) | [HG Phase function](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush)  | Disney SSS + Analytically-Integrated Translucency + [Baked Textured Thickness](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.hlsl)  
Specular Term | Two-lobe Blinn-Phong | KSK | Dual GGX | GGX  

## 1\. Diffuse Reflectance Term

### 1-1\. Diffusion Profile  

Currently, all real time approaches are based on the diffusion profile(**14.4.2 Rendering with Diffusion Profile** of \[dEon 2007\]) rather than the [BSSRDF](https://www.pbr-book.org/3ed-2018/Color_and_Radiometry/Surface_Reflection#TheBSSRDF).  

By using the diffusion profile, the subsurface scattering, which was described by the BSSRDF, is simplified by scattering the **amount** of light (technically, the **irradiance E**) of each location to the vicinal locations according to the weights indicated by the diffusion profile. Note that the **outgoing** irradiance E can also be called **radiant exitance M** and might be called **radiosity B** in the last century. Evidently, an equivalent gather operation can be used to replace the scatter operation, and the total **radiant exitance** can be considered as $\displaystyle \operatorname{M}(p_0) = \int_{S_{p_0}} \operatorname{R}(p, p_0) \cdot \operatorname{E}(p) \, dp$ where the $\displaystyle \operatorname{R}(p, p_0)$ is the diffusion profile. And, currently, all real time approaches assume that the material is homogeneous. This means that the 2D diffusion profile $\displaystyle \operatorname{R}(p, p_0)$ is radially symmetric, and can be reduced to the 1D diffusion profile $\displaystyle \operatorname{R}(\operatorname{distance}(p, p_0))$. And for the diffuse term, the outgoing radiance is assumed to be the same in all directions. Thus, the diffuse term can be simplified to $\displaystyle \operatorname{L}_o(p_0) = \frac{\operatorname{M}(p_0)}{\pi} = \frac{1}{\pi} \cdot \int_{S_{p_0}} \operatorname{R}(\operatorname{distance}(p_0, p)) \cdot \operatorname{E}(p) \, dp = \frac{1}{\pi} \cdot \int_{S_{p_0}} \operatorname{R}(\operatorname{distance}(p_0, p)) \cdot \pi \cdot \operatorname{L_i}(p) \, dp = \int_{S_{p_0}} \operatorname{R}(\operatorname{distance}(p_0, p)) \cdot \operatorname{L_i}(p) \, dp$.  

However, things are far from simple. Although the proposals based on the diffusion profile are much simpler than the BSSRDF, a general 2D convolution is still too expensive for real time rendering. Actually, according to \[dEon 2007\], if the width (technically, the range of the significant contribution domain) of the diffusion profile is about 16 mm, and the width of pixel is about 0.25 mm, we would need 4096(64 x 64) samples per pixel in the shader. Thus, we have to propose more efficient approaches to settle this problem.

### 1-2\. Preintegrated
The **diffuse reflectance** term of NVIDIA FaceWorks and the **Preintegrated Skin** [Shading Model](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/MaterialProperties/LightingModels/) of UE4 is based on the **Preintegrated** \[Penner 2011\].  

In real time rendering, the light is assumed to be the punctual light rather than the area light. The [Delta Distribution](https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/Sampling_Light_Sources#LightswithSingularities) is applied, and the reflectance equation is simplified to $\displaystyle \operatorname{L}_o(p, \omega_o) = \int_\Omega \operatorname{BRDF}(p, \omega_o, \omega_i) \cdot \operatorname{L_i}(p, \omega_i) \cdot |\cos(\theta_i)| \, d\omega_i = \operatorname{BRDF}(p, \omega_o, \omega_i) \otimes \operatorname{E_{L}}(p) \otimes |\cos(\theta)|$ where the $\displaystyle \operatorname{E_{L}}(p)$ is the irradiance perpendicular to the light direction. And since the diffuse BRDF equals $\displaystyle \frac{c_{diffuse}}{\pi}$ which is irrelevant to the the $\displaystyle w_o$ and the $\displaystyle w_i$, the reflectance equation can be simplified further to $\displaystyle \operatorname{L}_o(p) = \frac{\operatorname{c_{diffuse}}(p)}{\pi} \otimes \operatorname{E_{L}}(p) \otimes |\cos(\theta)|$. Thus, the diffuse term is simplified to $\displaystyle \operatorname{L}_o(p_0) = \int_{S_{p_0}} \operatorname{R}(\operatorname{distance}(p, p_0)) \cdot \operatorname{L_i}(p) \, dp = \int_{S_{p_0}} \operatorname{R}(\operatorname{distance}(p, p_0)) \cdot \frac{\operatorname{c_{diffuse}}(p)}{\pi} \cdot \operatorname{E_{L}}(p) \cdot |\cos(\theta)| \, dp$.  

The main idea of \[Penner 2011\] is that the $\displaystyle \frac{\operatorname{c_{diffuse}}(p)}{\pi} \cdot \operatorname{E_L}(p)$ is assumed to be the constant $\displaystyle \frac{\operatorname{c_{diffuse}}(p_0)}{\pi} \cdot \operatorname{E_L}(p_0)$ for all vicinal locations, and thus the $\displaystyle \operatorname{R}(\operatorname{distance}(p, p_0)) \cdot |\cos(\theta)|$ part of the diffuse term can be **preintegrated** and stored in a LUT(Look Up Texture) which is called the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$. The $\displaystyle \theta$ is merely the traditional $\displaystyle \operatorname{dot}(N,L)$, and the $\displaystyle \frac{1}{r}$, which is called **curvature** by \[Penner 2011\], can be calculated on-the-fly as $\displaystyle \frac{1}{r} = \frac{\operatorname{ddx}(N)}{\operatorname{ddx}(P)}$. However, the on-the-fly method may be inaccurate since the FaceWorks chooses to precompute the curvature instead. In conclusion, the diffuse term can be calculated as $\displaystyle \operatorname{D}(\operatorname{dot}(N,L), \frac{\operatorname{ddx}(N)}{\operatorname{ddx}(P)}) \otimes \frac{\operatorname{c_{diffuse}}(p)}{\pi} \otimes \operatorname{E_{L}}(p)$.
 
Usually, the diffusion profile is normalized which indicates the energy conservation. This means that $\displaystyle \int_{-\pi}^{\pi} R(2r\sin(\frac{x}{2})) \,dx = 1$. However, according to \[Penner 2011\], $\displaystyle \operatorname{D}(\theta, \frac{1}{r}) = \frac{\int_{-\pi}^{\pi} | \cos (\theta + x) | \cdot R(2r\sin(\frac{x}{2})) \,dx}{\int_{-\pi}^{\pi} R(2r\sin(\frac{x}{2})) \,dx}$ where denominator is added to make sure the diffusion profile is normalized.

In the GPU Pro 2, the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$ is calculated by **integrateDiffuseScatteringOnRing**. And there are some points to note.  
1. \[Penner 2011\] merely follows \[dEon 2007\] and the diffusion profile is approximated by the Gaussians (the **Scatter** in the code). However, the motivation of \[dEon 2007\] is that the [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) is a [separable filter](https://en.wikipedia.org/wiki/Separable_filter), and thus the general 2D convolution can be replaced by 1D convolutions to improve the performance. In my opinion, it is acceptable to perform a general 2D convolution even by using the exact accurate diffusion profile, since the approach proposed by \[Penner 2011\] **pre-integrates** the convolution, and the efficiency doesn't matter too much for offline precomputing.  
2. The **pre-integral** is performed on a ring rather than on a sphere. This is reasonable since it is assumed that the diffusion profile is radially symmetric.  
3. In the FaceWorks, according to the **numerical quadrature**, the funtion value $\operatorname{f}(x)$ is multiplied by the difference of the domain $\displaystyle \operatorname{\Delta}x$ (the **scale** in the code).  
However, in the GPU Pro 2, there is no such code like **scale** since the $\displaystyle \operatorname{\Delta}x$ appears in both numerator and denominator, and the it is not necessary to multiply $\displaystyle \operatorname{f}(x)$ by $\displaystyle \operatorname{\Delta}x$.  

In the FaceWorks, the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$ is calculated by **GFSDK_FaceWorks_GenerateCurvatureLUT**. However, there is some subtle modification.  
1. The $\displaystyle 2r\sin(\frac{x}{2})$ is replaced by the $\displaystyle rx$ (the **delta** in the code). Technically, the $\displaystyle 2r\sin(\frac{x}{2})$ is more correct since the diffusion profile describes the light absorption inside the medium rather than over the surface. Perhaps the $\displaystyle 2r\sin(\frac{x}{2})$ and the $\displaystyle rx$ are close when the $\displaystyle x$ is small.  
2. The denominator $\displaystyle \int_{-\pi}^{\pi} R(2r\sin(\frac{x}{2})) \,dx$ is omitted perhaps due to the fact that the diffusion profile has been normalized. Actually, I try to calculate the denominator by myself, and I find the denominator is really close to one.  
3. In the GPU Pro 2, three normals should be used for different RGB components and the LUT should be sampled three times according to three different $\displaystyle \theta$s. Perhaps this method is not efficient and the FaceWorks detaches the $\displaystyle \operatorname{dot}(N,L)$, which denotes the part of the integral where x is close to zero and the diffuse profile is close to one, from the total integral $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$. Evidently, the remaining part of the integral is relatively small, and thus FaceWorks maps the remaining part of the integral from [-0.25, 0.25] to [0, 1] to fully use the precision of the texture (the **rgbAdjust** in the code). The **GFSDK_FaceWorks_EvaluateSSSDirectLight** is used to calculate the diffuse term. The LUT is only sampled once and three normals are used to calculate the $\displaystyle \operatorname{dot}(N,L)$ which is detached from the total integral. 

### 1-3\. Separable SSS
The **diffuse reflectance** term of the **Subsurface Profile** [Shading Model](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/MaterialProperties/LightingModels/) **without** [Enable Burley](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/) of UE4 is based on the **Separable SSS** \[Jimenez 2012\].  

The approach of \[dEon 2007\] is to approximate the diffusion profile by the weighted sum of 6 Gaussians, and thus the general 2D convolution can be replaced by 12(2 x 6) 1D convolutions since the [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) is a [separable filter](https://en.wikipedia.org/wiki/Separable_filter). However, the approach proposed by \[dEon 2007\] is applied in texture space which is too weird according to the convention of the real time rendering. And the screen space approach is proposed by \[Jimenez 2009\]. However, the approach proposed by \[Jimenez 2009\] still needs 12(2 x 6) passes to perform the 12(2 x 6) 1D convolutions. Evidently, this is still too expensive for real time rendering. And thus, the 2 passes approach is proposed by \[Jimenez 2012\].    

According to the **numerical quadrature**, the funtion value sampled from the irradiance texture should be multiplied by the difference of the domain $\displaystyle \operatorname{\Delta} p_i$. \[dEon 2007\] proposed the **stretch texture**, where the difference of the world position is stored, to described the $\displaystyle \operatorname{\Delta} p_i$. Definitely, the screen space depth can be used to calculate the world position and thus the $\displaystyle \operatorname{\Delta} p_i$ can be obtained. However, the **stretch factor** proposed by \[Jimenez 2009\] is not proportional to the difference of the world position, and in my opinion, is empirical.  

The the demo source code of \[Jimenez 2012\] is provided by \[Jimenez 2015\]. Perhaps you can not believe it but it is really the truth. **The demo source code provided by \[Jimenez 2015\] has nothing to do with \[Jimenez 2015\]**. This is really arcane, and I do spend some time to realize this fact.   

The main idea of \[Jimenez 2012\] is that in real time rendering, the non-separable diffusion profile is represented by the discretized kernel where the SVD can be applied, and the SVD indicates that the diffusion profile kernel can be approximated by a separable kernel $\displaystyle \operatorname{M}(x_o, y_o) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{S}(\Delta x)) \cdot \operatorname{S^T}(\Delta y)$ where $\displaystyle \operatorname{S}(\Delta x) = \operatorname{R}(\frac{\Delta x \cdot \text{width}}{0.001 + \text{falloff}}) \cdot \text{strength} + \operatorname{\delta}(\Delta x) \cdot (1 - \text{strength})$ where **R** denotes the 1D diffusion profile and $\displaystyle \operatorname{\delta}(\Delta x)$ denotes the [delta function](https://en.wikipedia.org/wiki/Dirac_delta_function) such that $\displaystyle \operatorname{\delta}(0) = 1$.  

The $\displaystyle \operatorname{S}(\Delta x)$ is calculated by the **calculateKernel** in the demo source code provided by \[Jimenez 2015\] and the **ComputeMirroredSSSKernel** in the UE4. And there are some points to note.  
1. The **strength**, which is the **SubsurfaceColor** in the UE4, is to lerp between the SSS diffuse term $\displaystyle \operatorname{R}(\frac{\Delta x \cdot \text{width}}{0.001 + \text{falloff}})$ and the conventional diffuse term $\displaystyle \operatorname{\delta}(\Delta x)$. Evidently, when the **strength** equals 0, since $\displaystyle \operatorname{S}(\Delta x) = \displaystyle \operatorname{\delta}(\Delta x)$ and $\displaystyle \operatorname{\delta}(0) = 1$, the formula is reduced to the conventional diffuse term $\displaystyle \operatorname{M}(x_o, y_o) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{S}(\Delta x)) \cdot \operatorname{S^T}(\Delta y) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{\delta}(\Delta x)) \cdot \operatorname{\delta}(\Delta y) = \operatorname{E}(x_o, y_o)$. The default of the **strength** in the demo source code is (0.48, 0.41, 0.28).  
2. According to \[dEon 2007\], the width of the diffusion profile is about 16 mm. The **falloff**, which is the **FalloffColor** in the UE4, is to make the diffusion profile narrower, and thus the width of the diffusion profile in the demo source code is reduced to 6(3x2) mm (the **RANGE** in the **calculateKernel** in the code). The default of the **falloff** in the demo source code is (1.0, 0.37, 0.3).  
3. Actually, the demo source code demonstrates that the $\displaystyle \frac{\Delta x}{0.001 + \text{falloff}}$ is passed to the diffusion profile $\displaystyle \operatorname{R}(r)$ directly without the **width** in the formula. This implies the **width** in the formula is actually fixed at 1.
4. According to the **numerical quadrature**, the function value sampled from the irradiance texture should be multiplied by the difference of the domain the $\displaystyle \operatorname{\Delta} x$ and the $\displaystyle \operatorname{\Delta} y$ (the **area** in the **calculateKernel** in the code). And the demo source code demonstrates that the deviations of the locations of the samples in world space (in mm) is fixed and stored in the **w** component of the **kernel** member of the **SeparableSSS** class. Thus, the mere purpose of the **SSSSBlurPS** in the shader code is to transform the deviations from world space to texture space. Assuming that the deviations are from the origin of the Y axis, the transformation can be calculated as $\displaystyle \text{TextureSpace} =  \frac{1}{2} \times\frac{1}{\tan(\text{FOVY} \times 0.5)} \times \frac{1}{\text{ViewPositionZInWorldSpaceUnit}} \times \frac{1}{1000 \times \text{MetersPerWorldSpaceUnit}} \times \text{WorldSpaceDeltaXInMM}$ where the 1000 is to transform from mm to m, the $\displaystyle \frac{1}{\tan(\text{FOVY} \times 0.5)}$ is the second row and the second column of the projection matrix, and the 2 is to transform from NDC to texture space. However, since the width of the diffusion profile is fixed at 6(3x2) mm and the $\displaystyle \frac{\Delta x}{0.001 + \text{falloff}}$ is passed to the diffusion profile $\displaystyle \operatorname{P}(r)$ directly without the $\displaystyle w$ in the formula, the **sssWidth**, which is **ScatterRadius** in the UE4, is impossible to be considered as the **width** of the diffusion profile or the **width** in the formula. And since the shader code of the demo source code demonstrates that the transformation is calculated as $\displaystyle \text{TextureSpace} = \frac{1}{\tan(\text{FOVY} \times 0.5)} \times \frac{1}{\text{ViewPositionZInWorldSpaceUnit}} \times\frac{\text{sssWidth}}{3} \times \text{WorldSpaceDeltaXInMM}$, by comparing these two formulas, a hypothesis can be proposed that $\displaystyle \text{MetersPerWorldSpaceUnit} = \frac{3}{1000 \times 2 \times \text{sssWidth}}$. The default of the **sssWidth** in the demo source code is 0.012, and thus the hypothesis implies that the **MetersPerWorldSpaceUnit** of the demo is $\displaystyle \frac{1}{8}$. Actually, I check the vertex data of the head mesh in the demo, and fortunately, I find the vertex data is consistent with this result.  
5. The **SSSS_STRENGTH_SOURCE** in the shader code has nothing to do with the **strength** in the paper at all. In the demo source code, the **SSSS_STREGTH_SOURCE** is the alpha channel of the albedo texture, and is used to skip the pixels which represent the eyebrow rather than the skin. However, this empirical **strength** value is adopted by both UE4 and Unity3D. The equivalent in UE4 is called [Opacity Map](https://docs.unrealengine.com/4.26/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/#materialinputchannels), and the equivalent in Unity3D is called [Subsurface Mask Map](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Material-Type.html).  
   
### 1-4\. Disney SSS
The **diffuse reflectance** term of [Unity3D](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html) and the **Subsurface Profile** [Shading Model](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/MaterialProperties/LightingModels/) with [Enable Burley](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/) of UE4 is based on the **Disney SSS** \[Golubev 2018\].  

#### 1-4-1\. Bilateral Filter  

The approach of \[Mikkelsen 2010\] is used by \[Golubev 2018\] to the estimated surface area based on the screen space area.  

Let x be the point on the surface, and p is the perspective projection of x on the screen space. We have $\displaystyle dx = \frac{\cos^3(\phi_i)\|x\|^2}{\cos(\phi_j)} \, dp$ where $\displaystyle \phi_i$ is the angle between negative z axis $\displaystyle -\overrightarrow{z}$ and $\displaystyle \overrightarrow{p}$, and $\displaystyle \phi_j$ is the angle between surface normal $\displaystyle \overrightarrow{n}$ and $\displaystyle -\overrightarrow{p}$. Proof: Let $\displaystyle d\omega$ be the same differential solid angle subtended by the differential area $\displaystyle dp$ and $\displaystyle dx$. By the [Equation (5.6) of PBR Book](https://pbr-book.org/3ed-2018/Color_and_Radiometry/Working_with_Radiometric_Integrals#IntegralsoverArea), we have $\displaystyle d\omega = \cos(\phi_j)\frac{1}{\|x\|^2} \, dx$ and $\displaystyle d\omega = \cos(\phi_i)\frac{1}{\frac{1}{\cos^2(\phi_i)}} \, dp = \cos^3(\phi_i) \, dp$. Since $\displaystyle d\omega$ is the same, we have $\displaystyle \cos(\phi_j)\frac{1}{\|x\|^2} \, dx = \cos^3(\phi_i) \, dp$, namely $\displaystyle dx = \frac{\cos^3(\phi_i)\|x\|^2}{\cos(\phi_j)} \, dp$.  

Let $\displaystyle \operatorname{{\Delta x}_{xy}} = \sqrt{{(x.x - x_0.x)}^2 + {(x.y - x_0.y)}^2}$ and $\displaystyle {\Delta x}_z = |x.z - x_0.z|$. We have $\displaystyle \|x - x_0\| = \sqrt{{{\Delta x}_{xy}}^2 + {{\Delta x}_z}^2}$. And $\displaystyle \operatorname{{\Delta x}_{xy}}$ can be approximated by $\displaystyle K_{p_0} \cdot \|p - p_0\|$ where $\displaystyle K_{p_0} = \frac{2 \cdot r_{max} \cdot |\cos \theta_0|}{d \cdot \cos \phi_0}$. The form of this equation may remind us of the one degree [Taylor polynomial](https://en.wikipedia.org/wiki/Taylor%27s_theorem), but $\displaystyle r_{max}$ and $\displaystyle d$ are the macro quantities which can **NOT** be explained by the micro differential.  

When the diffusion profile $\displaystyle \operatorname{R}(x)$ is the Gaussian function $\displaystyle \operatorname{G}(\sigma, x)$, by [Integration by Substitution](https://en.wikipedia.org/wiki/Integration_by_substitution), the integral can be transformed from the surface area to the screen space area $\displaystyle \int_{S_{x_0}} \operatorname{R}(\|x - x_0\|) \cdot \operatorname{E}(x) \, dx = \int_{S_{p_0}} \operatorname{G}(\sigma, \|x - x_0\|) \cdot \operatorname{E}(x) \, dx = \frac{2\pi\sigma^2}{{K_{p_0}}^2}\int_{S_{p_0}} \operatorname{G}(\frac{\sigma}{K_{p_0}}, \|p - p_0\|) \cdot \operatorname{G}(\sigma, {\Delta x}_z) \cdot \operatorname{E}(p) \cdot \operatorname{x'_p}(p) \, dp$. The surface area $\displaystyle S_{x_0}$, of which the radius is 8mm by \[dEon 2007\], is relatively small, and thus the $\displaystyle \operatorname{x'_p}(p)$ can be approximated by the $\displaystyle \operatorname{x'_p}(p_0)$. And since the diffusion profile $\displaystyle \operatorname{R}(x)$ is normalized, we have $\displaystyle \frac{2\pi\sigma^2}{{K_{p_0}}^2}\int_{S_{p_0}} \operatorname{G}(\frac{\sigma}{K_{p_0}}, \|p - p_0\|) \cdot \operatorname{G}(\sigma, {\Delta x}_z) \cdot \operatorname{x'_p}(p) \, dp = 1$. This means that the $\displaystyle K_{p_0}$ does **NOT** need to be calculated.  

However, the diffusion profile $\displaystyle \operatorname{R}(x)$ of \[Golubev 2018\] is **NOT** the Gaussian function, and thus the formula provided by \[Mikkelsen 2010\] does **NOT** apply. The Unity3D and the UE4 both merely assume that $\displaystyle K_{p_0} = 1$, and the $\displaystyle \|x - x_0\|$ can be estimated as $\sqrt{{\|p - p_0\|}^2 + {{\Delta x}_z}^2}$.  

The **Bilateral Filter** is controlled by the macro **SSS_BILATERAL_FILTER** in the Unity3D and the macro **USE_BILATERAL_FILTERING** in the UE4.  


#### 1-4-2\. Importance Sampling  
The normalized diffusion profile $\displaystyle \operatorname{R}(x) = \frac{s}{8\pi}(e^{-sr}+e^{-\frac{sr}{3}})$ is used as PDF by \[Golubev 2018\].  

However, the normalized diffusion profile is 1D, and thus only the 1D radial distance r of the sample can be deduced. Both Unity3D and UE4 use the **Fibonacci sequence**, which represents the [Golden ratio](https://en.wikipedia.org/wiki/Golden_ratio#Relationship_to_Fibonacci_sequence), to determine the direction.  

The **Fibonacci sequence** is calculated by the **SampleDiskFibonacci** in the Unity3D and the **FIBONACCI_SEQUENCE_ANGLE** in the UE4.  


#### 1-4-3\. Properties between Unity3D and UE4  
Formula Name | [Unity3D Name](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html) | [Unity3D Default](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/RenderPipelineResources/Skin%20Diffusion%20Profile.asset) | [UE4 Name](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/) | [UE4 Default](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Source/Runtime/Engine/Classes/Engine/SubsurfaceProfile.h)  
:-: | :-: | :-: | :-: | :-:  
A | Diffuse Color | N/A | SurfaceAlbedo | (0.91058, 0.338275, 0.2718)  
S | ScatteringDistance | (0.7568628, 0.32156864, 0.20000002) | MeanFreePathColor\*MeanFreePathDistance | (1.0\*(1.2\*2.229), (0.1983/2.229)\*(1.2\*2.229), (0.1607/2.229)\*(1.2\*2.229))  
N/A | WorldScale (MetersPerUnit) | 1 | WorldUnitScale (UnitsPerCentimeter) | 0.1  





## 2\. Diffuse Transmittance Term

### 2-1\. Deep Scatter
The **diffuse transmittance** term of the FaceWorks is based on the **16.3 Simulating Absorption Using Depth Maps** of \[Green 2004\].  

The main idea of \[Green 2004\] is that the objects are assumed to be convex, and thus the thickness (the distance a light ray travels inside an object) can be estimated by using the shadow maps. According to the thickness, the [Beer–Lambert law](https://en.wikipedia.org/wiki/Beer%E2%80%93Lambert_law) can be applied to calculate the transmittance coefficient.  

In the FaceWorks, the **thickness** is calculated by **GFSDK_FaceWorks_EstimateThicknessFromParallelShadowPoisson32** and the **transmittance coefficient** is calculated by **GFSDK_FaceWorks_EvaluateDeepScatterDirectLight**.  

### 2-2\. Analytically-Integrated Translucency  
The **diffuse transmittance** term of demo source code provided by \[Jimenez 2015\] is based on \[Jimenez 2010\].  

The main idea of \[Jimenez 2010\] is that the approach proposed by \[Green 2004\] is applied to calculate the thickness while the transmittance coefficient is calculated based on the diffusion profile rather than the **Beer–Lambert law**. According to \[Jimenez 2010\], the idea of the **14.5.3 Modified Translucent Shadow Maps** of \[dEon 2007\] is applied, and the transmittance coefficient is calculated as $\displaystyle \operatorname{T}(d) = \int_0^\infin 2 \pi r \cdot \operatorname{R} (\sqrt{r^2 + d^2}) \, dr$ where the R is the 1D diffusion profile and the r is the distance over the surface. If the diffusion profile is approximated by the Gaussians proposed by \[Green 2004\], the result of the integral is analytical and can be calculated as $\displaystyle \operatorname{T}(d) = \sum_i^k w_i e^{\frac{-d^2}{v_i}}$.  

The **transmittance coefficient** is calculated by the **SSSSTransmittance** in the demo source code provided by \[Jimenez 2015\]. And there are some points to note.  
1. The demo uses **0.005** to shrink the object in the normal direction to avoid artifacts. Evidently, this value is proportional to the $\displaystyle \frac{1}{\text{MetersPerWorldSpaceUnit}}$.  
2. Actually, the mere purpose of the **scale** in the shader code is to transform the thickness from world space unit to mm. The shader code of the demo source code demonstrates that the **scale** is calculated as $\displaystyle 8.25 \times (1 - \text{translucency}) \times \frac{1}{\text{sssWidth}}$. According to the **1-3\. Separable SSS** of this page, the $\displaystyle \frac{1}{\text{sssWidth}}$ can be substituted as $\displaystyle \frac{1000 \times 2 \times \text{MetersPerWorldSpaceUnit}}{3}$, and thus the **scale** is actually calculated as $\displaystyle 8.25 \times (1 - \text{translucency}) \times \frac{2}{3} \times 1000 \times \text{MetersPerWorldSpaceUnit}$. The default of the **translucency** in the demo source code is 0.83, and thus the value of $\displaystyle 8.25 \times (1 - \text{translucency}) \times \frac{2}{3}$ is 0.935 which is really close to 1. This implies that the **scale** is actually calculated as $\displaystyle 1000 \times \text{MetersPerWorldSpaceUnit}$ which is exactly the transformation from world space unit to mm.  

### 2-3\. Baked Textured Thickness  
The **diffuse transmittance** term of Unity3D is based on \[Golubev 2018\].  

\[Golubev 2018\] follows the analytically-integrated formula of \[Jimenez 2010\] while the diffuse profile of \[Christensen 2015\] is applied. And thus, we have that $\displaystyle \operatorname{T}(d) = \int_0^\infin 2 \pi r \cdot \operatorname{R} (\sqrt{r^2 + d^2}) \, dr = \frac{1}{4} A (e^{-sd} + 3e^{-\frac{sd}{3}})$.  

There are two [Transmission Mode](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html)s: **Thick Object** and **Thin Object**. The **Thick Object** mode merely follows the approach of \[Jimenez 2010\] which uses the shadow map to calculate the thickness. And the **Thin Object** mode uses the baked textured thickness which can be provided by the [Substance](https://substance3d.adobe.com/documentation/bake/thickness-map-from-mesh-172818642.html).  

In the [Unity3D](https://github.com/Unity-Technologies/Graphics), the **thickness** is calculated by the **FillMaterialTransmission**, the **ShouldEvaluateThickObjectTransmission** and the **EvaluateTransmittance_Punctual**.  


## 3\. Specular Term  

### 3-1\. Two-lobe Blinn-Phong  
TODO  
  
### 3-2\. Dual GGX    
TODO  

## References
\[Kelemen 2001\] [Csaba Kelemen, László Szirmay-Kalos. "A Microfacet Based Coupled Specular-Matte BRDF Model with Importance Sampling." EGSR 2001.](http://cg.iit.bme.hu/~szirmay/scook_link.htm)  
\[Green 2004\] [Simon Green. "Chapter 16. Real-Time Approximations to Subsurface Scattering." GPU Gems 1.](https://developer.nvidia.com/gpugems/gpugems/part-iii-materials/chapter-16-real-time-approximations-subsurface-scattering)  
\[dEon 2007\] [Eugene dEon, David Luebke. "Advanced Techniques for Realistic Real-Time Skin Rendering." GPU Gem 3.](https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-14-advanced-techniques-realistic-real-time-skin)  
\[Jimenez 2009\] [Jorge Jimenez, Veronica Sundstedt, Diego Gutierrez. "Screen-Space Perceptual Rendering of Human Skin." ACM TAP 2009.](https://www.iryoku.com/sssss/)  
\[Jimenez 2009\] Jorge Jimenez, Diego Gutierrez. "Screen-Space Subsurface Scattering." GPU Pro 1.  
\[Jimenez 2010\] [Jorge Jimenez, David Whelan, Veronica Sundstedt, Diego Gutierrez. "Real-Time Realistic Skin Translucency." IEEE 2010.](http://www.iryoku.com/translucency/)  
\[Mikkelsen 2010\] [Morten Mikkelsen. "Skin Rendering by Pseudo–Separable Cross Bilateral Filtering." Naughty Dog.](https://mmikk.github.io/papers3d/cbf_skin.pdf)  
\[Penner 2011\] Eric Penner, George Borshukov. "Pre-Integrated Skin Shading." GPU Pro 2.  
\[Penner 2011\] [Eric Penner. "Pre-Integrated Skin Shading." SIGGRAPH 2011.](http://advances.realtimerendering.com/s2011/)  
\[Lazarov 2011\] [Dimitar Lazarov. "Physically Based Lighting in Call of Duty : Black Ops." SIGGRAPH 2011.](http://advances.realtimerendering.com/s2011/)  
\[Jimenez 2012\] [Jorge Jimenez, Adrian Jarabo, Diego Gutierrez. "Separable Subsurface Scattering." Technical Report 2012.](https://graphics.unizar.es/publications.html#year_2012)   
\[Jimenez 2012\] [Jorge Jimenez, Adrian Jarabo, Diego Gutierrez, Etienne Danvoye, Javier von der Pahlen. "Separable Subsurface Scattering and Photorealistic Eyes Rendering." SIGGRAPH 2012.](http://advances.realtimerendering.com/s2012/index.html)  
\[Jimenez 2015\] [Jorge Jimenez, Karoly Zsolnai, Adrian Jarabo1, Christian Freude, Thomas Auzinger, Xian-Chun Wu, Javier von der Pahlen, Michael Wimmer, Diego Gutierrez. "Separable Subsurface Scattering." EGSR 2015.](http://www.iryoku.com/separable-sss/)  
\[Christensen 2015\] [Per Christensen, Brent Burley. "Approximate Reflectance Profiles for Efficient Subsurface Scattering." SIGGRAPH 2015.](https://graphics.pixar.com/library/)  
\[Golubev 2018\] [Evgenii Golubev. "Efficient Screen-Space Subsurface Scattering Using Burley's Normalized Diffusion in Real-Time." SIGGRAPH 2018.](https://zero-radiance.github.io/post/sampling-diffusion/)  
