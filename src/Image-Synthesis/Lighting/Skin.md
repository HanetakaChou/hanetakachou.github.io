# Skin  

N/A | [NVIDIA FaceWorks](https://github.com/NVIDIAGameWorks/FaceWorks/blob/master/doc/slides/FaceWorks-Overview-GTC14.pdf) | [Demo Source Code of Jimenez 2015](http://www.iryoku.com/separable-sss/) | UE4 | Unity3D  
:-: | :-: | :-: | :-: | :-: 
Diffuse Reflectance Term | Preintegrated | [Separable SSS](https://graphics.unizar.es/publications.html#year_2012) | [Preintegrated](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush#L754) + [Disney Diffuse](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush#L585) + [Separable SSS](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Source/Runtime/Engine/Private/Rendering/SeparableSSS.cpp) + [Disney SSS](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/SubsurfaceBurleyNormalized.ush#L1163) | [Disney Diffuse](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/Lit/Lit.hlsl#L1349) + [Disney SSS](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.compute#L248)  
Diffuse Transmittance Term | Deep Scatter | [Analytically-Integrated Translucency](http://www.iryoku.com/translucency/) | [HG Phase function](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush#L609)  | Disney SSS + Analytically-Integrated Translucency + [Baked Textured Thickness](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.hlsl#L225)  
Specular Term | Two-lobe Blinn-Phong | KSK | [Dual GGX](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/ShadingModels.ush#L595) | GGX  


Diffuse Term | NVIDIA FaceWorks | Demo of \[Jimenez 2015\] | UE4 | Unity3D  
:-: | :-: | :-: | :-: | :-:  
BRDF |  Lambert Diffuse | Lambert Diffuse | Disney Diffuse| Disney Diffuse  
Transmittance| Deep Scatter | Analytically-Integrated Translucency with the Diffusion Profile approximated by the Gaussians | HG Phase function | Analytically-Integrated Translucency with the Disney Diffusion Profile  

Specular Term | NVIDIA FaceWorks | Demo of \[Jimenez 2015\] | UE4 | Unity3D  
:-: | :-: | :-: | :-: | :-:  
BRDF | Two-Lobe Blinn-Phong | KSK | Two-Lobe Trowbridge-Reitz | Trowbridge-Reitz  

## 1\. Diffusion Profile  

The **diffusion profile** $\displaystyle \operatorname{R}(\Delta x, \Delta y, (\Delta z))$ by "14.4.2 Rendering with Diffusion Profile" of \[dEon 2007\] is also called the **radial profile** $\displaystyle \operatorname{S_p}(\overrightarrow{p_o}, \overrightarrow{p_i})$ by "Equation \(11.6\)" of [PBR Book](https://pbr-book.org/3ed-2018/Volume_Scattering/The_BSSRDF#eq:separable-bssrdf).  

And by "Advantages of a Sum-of-Gaussians Diffusion Profile" of \[dEon 2007\] and "Equation \(11.9\)" of [PBR Book](https://pbr-book.org/3ed-2018/Volume_Scattering/The_BSSRDF#eq:distance-bssrdf), by assuming the material is homogeneous, the diffusion profile is isotropic (radially symmetric). This means that the diffusion profile can be reduced to the 1D function $\displaystyle \operatorname{R}(\Delta x, \Delta y) = \operatorname{R}(\sqrt{{\Delta x}^2 +{\Delta y}^2 (+ {\Delta z}^2))} = \operatorname{R}(r) = \operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|)$ and $\displaystyle \operatorname{S_p}(\overrightarrow{p_o}, \overrightarrow{p_i}) = \operatorname{S_r}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|)$.  

By the "Equation \(11.7\)" of [PBR Book](https://pbr-book.org/3ed-2018/Volume_Scattering/The_BSSRDF#eq:separable-bssrdf-directional), the calculation of the subsurface scattering can be simplified as $\displaystyle \operatorname{L_o}(\overrightarrow{p_o}, \overrightarrow{\omega_o}) = \int_{{\mathbb{R}}^2} \left\lparen \int_\Omega \operatorname{S}(\overrightarrow{p_o}, \overrightarrow{\omega_o}, \overrightarrow{p_i}, \overrightarrow{\omega_i}) \operatorname{L_i}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) (\cos \theta_i)^+ \, d \overrightarrow{\omega_i} \right\rparen \, d \overrightarrow{p_i} \approx (1 - \operatorname{F_r}(\cos \theta_o)) \left\lparen \int_{{\mathbb{R}}^2} \operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|) \left\lparen \int_\Omega (1 - \operatorname{F_r}(\cos \theta_i)) \frac{1}{c} \frac{1}{\pi} \operatorname{L_i}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) (\cos \theta_i)^+ \, d \overrightarrow{\omega_i} \right\rparen \, d \overrightarrow{p_i} \right\rparen$ where $\displaystyle \operatorname{S}(\overrightarrow{p_o}, \overrightarrow{\omega_o}, \overrightarrow{p_i}, \overrightarrow{\omega_i})$ is the general BSSRDF term, $\displaystyle \operatorname{F_r}(\cos \theta))$ is the Fresnel term and $\displaystyle c = 1 - 2 \int_0^{\frac{\pi}{2}} \operatorname{F_r}(\cos \theta)) \sin \theta \cos \theta \, d \theta$ is the the first moment of the Fresnel term.  

By "SSS-NOTE-TRSM" of [Unity3D](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/Lit/Lit.hlsl#L1330), it is expensive to apply the first Fresnel term $\displaystyle 1 - \operatorname{F_r}(\cos \theta_o)$ after the diffusion profile term $\operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|)$, since we are forced to read the normal buffer after the blur pass. And thus, the calculation of the subsurface scattering is further simplified as $\displaystyle \operatorname{L_o}(\overrightarrow{p_o}, \overrightarrow{\omega_o}) = (1 - \operatorname{F_r}(\cos \theta_o)) \left\lparen \int_{{\mathbb{R}}^2} \operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|) \left\lparen \int_\Omega (1 - \operatorname{F_r}(\cos \theta_i)) \frac{1}{c} \frac{1}{\pi} \operatorname{L_i}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) (\cos \theta_i)^+ \, d \overrightarrow{\omega_i} \right\rparen \, d \overrightarrow{p_i} \right\rparen \approx \int_{{\mathbb{R}}^2} \operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|) \left\lparen \int_\Omega (1 - \operatorname{F_r}(\cos \theta_o)) (1 - \operatorname{F_r}(\cos \theta_i)) \frac{1}{c} \frac{1}{\pi} \operatorname{L_i}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) (\cos \theta_i)^+ \, d \overrightarrow{\omega_i} \right\rparen \, d \overrightarrow{p_i} = \int_{{\mathbb{R}}^2} \operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|) \operatorname{F_r}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) \, d \overrightarrow{p_i}$ where $\displaystyle \operatorname{F}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) = \int_\Omega (1 - \operatorname{F_r}(\cos \theta_o)) (1 - \operatorname{F_r}(\cos \theta_i)) \frac{1}{c} \frac{1}{\pi} \operatorname{L_i}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) (\cos \theta_i)^+ \, d \overrightarrow{\omega_i}$ is the **form factor F**. Although the terms **irradiance E** and **form factor F** may be interchangeably used, technically **irradiance E** should NOT be divided by $\displaystyle \pi$. This means that $\displaystyle \operatorname{E} = \pi \operatorname{F}$. Although the form factor was approximated by the Lambert diffuse BRDF in [NVIDIA FaceWork](https://github.com/NVIDIAGameWorks/FaceWorks) and [Demo of \[Jimenez 2015\]](https://github.com/iryoku/separable-sss), currently the more accurate Disney diffuse BRDF is provided in [UE4](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/BRDF.ush#L253) and [Unity3D](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.core/ShaderLibrary/BSDF.hlsl#L414).  

According to the equation $\displaystyle \operatorname{L_o}(\overrightarrow{p_o}, \overrightarrow{\omega_o}) = \int_{{\mathbb{R}}^2} \operatorname{R}(\| \overrightarrow{p_i} - \overrightarrow{p_o} \|) \operatorname{F}(\overrightarrow{p_i}, \overrightarrow{\omega_i}) \, d \overrightarrow{p_i}$, we merely need to calculate the form factor at each vicinal location $\displaystyle \overrightarrow{p_i}$ of the center location $\displaystyle \overrightarrow{p_o}$ and apply the blur pass to accumulate these form factors according to the weights by the diffusion profile.

## 1-1\. Texturing Mode

## 1-2\. Blur Pass

Blur Pass | NVIDIA FaceWorks | Demo of \[Jimenez 2015\]  | UE4 | Unity3D  
:-: | :-: | :-: | :-: | :-:  
PreIntegrated SSS | Demo | N/A | PreIntegrated Skin Shading Model | N/A  
Separable SSS | N/A | Demo | Subsurface Profile Shading Model without Enable Burley | N/A  
Disney SSS | N/A | N/A | Subsurface Profile Shading Model with Enable Burley | Subsurface Scattering Material Type  

Although the blur pass is much simpler than the general BSSRDF term, a general 2D convolution is still too expensive to be used in real time. By "Advantages of a Sum-of-Gaussians Diffusion Profile" of \[dEon 2007\], by assuming the range of the significant contribution domain of the red channel of the diffusion profile is 16 mm, 4096 (64 x 64) samples is required per pixel in the blur pass. Thus, more efficient method should be proposed to settle down this problem.  

## 1-1\. PreIntegrated SSS
The **diffuse reflectance** term of NVIDIA FaceWorks and the **Preintegrated Skin** [Shading Model](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/MaterialProperties/LightingModels/) of UE4 is based on the **Preintegrated** \[Penner 2011\].  

In real time rendering, the light is assumed to be the punctual light rather than the area light. The [Delta Distribution](https://www.pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/Sampling_Light_Sources#LightswithSingularities) is applied, and the reflectance equation is simplified to $\displaystyle \operatorname{L_o}(p, \omega_o) = \int_\Omega \operatorname{BRDF}(p, \omega_o, \omega_i) \cdot \operatorname{L_i}(p, \omega_i) \cdot |\cos(\theta_i)| \, d\omega_i = \operatorname{BRDF}(p, \omega_o, \omega_i) \otimes \operatorname{E_L}(p) \otimes |\cos(\theta)|$ where the $\displaystyle \operatorname{E_L}(p)$ is the irradiance perpendicular to the light direction. And since the diffuse BRDF equals $\displaystyle \frac{c_{diffuse}}{\pi}$ which is irrelevant to the the $\displaystyle w_o$ and the $\displaystyle w_i$, the reflectance equation can be simplified further to $\displaystyle \operatorname{L_o}(p) = \frac{\operatorname{c_{diffuse}}(p)}{\pi} \otimes \operatorname{E_L}(p) \otimes |\cos(\theta)|$. Thus, the diffuse term is simplified to $\displaystyle \operatorname{L_o}(p_o) = \int_{S_{p_o}} \operatorname{R}(\operatorname{distance}(p, p_o)) \cdot \operatorname{L_i}(p) \, dp = \int_{S_{p_o}} \operatorname{R}(\operatorname{distance}(p, p_o)) \cdot \frac{\operatorname{c_{diffuse}}(p)}{\pi} \cdot \operatorname{E_L}(p) \cdot |\cos(\theta)| \, dp$.  

The main idea of \[Penner 2011\] is that the $\displaystyle \frac{\operatorname{c_{diffuse}}(p)}{\pi} \cdot \operatorname{E_L}(p)$ is assumed to be the constant $\displaystyle \frac{\operatorname{c_{diffuse}}(p_o)}{\pi} \cdot \operatorname{E_L}(p_o)$ for all vicinal locations, and thus the $\displaystyle \operatorname{R}(\operatorname{distance}(p, p_o)) \cdot |\cos(\theta)|$ part of the diffuse term can be **preintegrated** and stored in a LUT(Look Up Texture) which is called the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$. The $\displaystyle \theta$ is merely the traditional $\displaystyle \operatorname{dot}(N,L)$, and the $\displaystyle \frac{1}{r}$, which is called **curvature** by \[Penner 2011\], can be calculated on-the-fly as $\displaystyle \frac{1}{r} = \frac{\operatorname{ddx}(N)}{\operatorname{ddx}(P)}$. However, the on-the-fly method may be inaccurate since the FaceWorks chooses to precompute the curvature instead. In conclusion, the diffuse term can be calculated as $\displaystyle \operatorname{D}(\operatorname{dot}(N,L), \frac{\operatorname{ddx}(N)}{\operatorname{ddx}(P)}) \otimes \frac{\operatorname{c_{diffuse}}(p)}{\pi} \otimes \operatorname{E_L}(p)$.
 
Usually, the diffusion profile is normalized which indicates the energy conservation. This means that $\displaystyle \int_{-\pi}^{\pi} R(2r\sin(\frac{x}{2})) \,dx = 1$. However, according to \[Penner 2011\], $\displaystyle \operatorname{D}(\theta, \frac{1}{r}) = \frac{\int_{-\pi}^{\pi} | \cos (\theta + x) | \cdot R(2r\sin(\frac{x}{2})) \,dx}{\int_{-\pi}^{\pi} R(2r\sin(\frac{x}{2})) \,dx}$ where denominator is added to make sure the diffusion profile is normalized.

In the GPU Pro 2, the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$ is calculated by **integrateDiffuseScatteringOnRing**. And there are some points to note.  
1. \[Penner 2011\] merely follows \[dEon 2007\] and the diffusion profile is approximated by the Gaussians (the **Scatter** in the code). However, the motivation of \[dEon 2007\] is that the [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) is a [separable filter](https://en.wikipedia.org/wiki/Separable_filter), and thus the general 2D convolution can be replaced by 1D convolutions to improve the performance. In my opinion, it is acceptable to perform a general 2D convolution even by using the exact accurate diffusion profile, since the approach proposed by \[Penner 2011\] **pre-integrates** the convolution, and the efficiency doesn't matter too much for offline precomputing.  
2. The **pre-integral** is performed on a ring rather than on a sphere. This is reasonable since it is assumed that the diffusion profile is radially symmetric.  
3. In the FaceWorks, according to the **numerical quadrature**, the funtion value $\operatorname{f}(x)$ is multiplied by the difference of the domain $\displaystyle \operatorname{\Delta}x$ (the **scale** in the code).  
However, in the GPU Pro 2, there is no such code like **scale** since the $\displaystyle \operatorname{\Delta}x$ appears in both numerator and denominator, and the it is not necessary to multiply $\displaystyle \operatorname{f}(x)$ by $\displaystyle \operatorname{\Delta}x$.  

In the FaceWorks, the $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$ is calculated by **GFSDK_FaceWorks_GenerateCurvatureLUT**. However, there is some subtle modification.  
1. The $\displaystyle 2r\sin(\frac{x}{2})$ is replaced by the $\displaystyle rx$ (the **delta** in the code). Technically, the $\displaystyle 2r\sin(\frac{x}{2})$ is more correct since the diffusion profile describes the light absorption inside the medium rather than over the surface. Perhaps the $\displaystyle 2r\sin(\frac{x}{2})$ and the $\displaystyle rx$ are close when the $\displaystyle x$ is small.  
2. The denominator $\displaystyle \int_{-\pi}^{\pi} R(2r\sin(\frac{x}{2})) \,dx$ is omitted perhaps due to the fact that the diffusion profile has been normalized. Actually, I try to calculate the denominator by myself, and I find the denominator is really close to one.  
3. In the GPU Pro 2, three normals should be used for different RGB components and the LUT should be sampled three times according to three different $\displaystyle \theta$s. Perhaps this method is not efficient and the FaceWorks detaches the $\displaystyle \operatorname{dot}(N,L)$, which denotes the part of the integral where x is close to zero and the diffuse profile is close to one, from the total integral $\displaystyle \operatorname{D}(\theta, \frac{1}{r})$. Evidently, the remaining part of the integral is relatively small, and thus FaceWorks maps the remaining part of the integral from [-0.25, 0.25] to [0, 1] to fully use the precision of the texture (the **rgbAdjust** in the code). The **GFSDK_FaceWorks_EvaluateSSSDirectLight** is used to calculate the diffuse term. The LUT is only sampled once and three normals are used to calculate the $\displaystyle \operatorname{dot}(N,L)$ which is detached from the total integral. 

## 1-3\. Separable SSS
The **diffuse reflectance** term of the **Subsurface Profile** [Shading Model](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/MaterialProperties/LightingModels/) **without** [Enable Burley](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/) of UE4 is based on the **Separable SSS** \[Jimenez 2012\].  

Note that the word "separable" in the "Separable SSS" has nothing to do with the "11.4.1 Separable BSSRDFs" of [PBR Book](https://pbr-book.org/3ed-2018/Volume_Scattering/The_BSSRDF#eq:separable-bssrdf).  

The approach of \[dEon 2007\] is to approximate the diffusion profile by the weighted sum of 6 Gaussians, and thus the general 2D convolution can be replaced by 12(2 x 6) 1D convolutions since the [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) is a [separable filter](https://en.wikipedia.org/wiki/Separable_filter). However, the approach proposed by \[dEon 2007\] is applied in texture space which is too weird according to the convention of the real time rendering. And the screen space approach is proposed by \[Jimenez 2009\]. However, the approach proposed by \[Jimenez 2009\] still needs 12(2 x 6) passes to perform the 12(2 x 6) 1D convolutions. Evidently, this is still too expensive for real time rendering. And thus, the 2 passes approach is proposed by \[Jimenez 2012\].    

According to the **numerical quadrature**, the funtion value sampled from the irradiance texture should be multiplied by the difference of the domain $\displaystyle \operatorname{\Delta} p_i$. \[dEon 2007\] proposed the **stretch texture**, where the difference of the world position is stored, to described the $\displaystyle \operatorname{\Delta} p_i$. Definitely, the screen space depth can be used to calculate the world position and thus the $\displaystyle \operatorname{\Delta} p_i$ can be obtained. However, the **stretch factor** proposed by \[Jimenez 2009\] is not proportional to the difference of the world position, and in my opinion, is empirical.  

The the demo source code of \[Jimenez 2012\] is provided by \[Jimenez 2015\]. Perhaps you can not believe it but it is really the truth. **The demo source code provided by \[Jimenez 2015\] has nothing to do with \[Jimenez 2015\]**. This is really arcane, and I do spend some time to realize this fact.   

The main idea of \[Jimenez 2012\] is that in real time rendering, the non-separable diffusion profile is represented by the discretized kernel where the SVD can be applied, and the SVD indicates that the diffusion profile kernel can be approximated by a separable kernel $\displaystyle \operatorname{M}(x_o, y_o) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{S}(\Delta x)) \cdot \operatorname{S^T}(\Delta y)$ where $\displaystyle \operatorname{S}(\Delta x) = \operatorname{R}(\frac{\Delta x \cdot \text{width}}{0.001 + \text{falloff}}) \cdot \text{strength} + \operatorname{\delta}(\Delta x) \cdot (1 - \text{strength})$ where **R** denotes the 1D diffusion profile and $\displaystyle \operatorname{\delta}(\Delta x)$ denotes the [delta function](https://en.wikipedia.org/wiki/Dirac_delta_function) such that $\displaystyle \operatorname{\delta}(0) = 1$.  

The $\displaystyle \operatorname{S}(\Delta x)$ is calculated by the **calculateKernel** in the demo source code provided by \[Jimenez 2015\] and the **ComputeMirroredSSSKernel** in the UE4. And there are some points to note.  
1. The **strength**, which is the **SubsurfaceColor** in the UE4, is to lerp between the SSS diffuse term $\displaystyle \operatorname{R}(\frac{\Delta x \cdot \text{width}}{0.001 + \text{falloff}})$ and the conventional diffuse term $\displaystyle \operatorname{\delta}(\Delta x)$. Evidently, when the **strength** equals 0, since $\displaystyle \operatorname{S}(\Delta x) = \displaystyle \operatorname{\delta}(\Delta x)$ and $\displaystyle \operatorname{\delta}(0) = 1$, the formula is reduced to the conventional diffuse term $\displaystyle \operatorname{M}(x_o, y_o) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{S}(\Delta x)) \cdot \operatorname{S^T}(\Delta y) = \sum_y (\sum_x \operatorname{E}(x_o + \Delta x, y_o + \Delta y) \cdot \operatorname{\delta}(\Delta x)) \cdot \operatorname{\delta}(\Delta y) = \operatorname{E}(x_o, y_o)$. The default of the **strength** in the demo source code is (0.48, 0.41, 0.28).  
2. According to \[dEon 2007\], the width of the diffusion profile is about 16 mm. The **falloff**, which is the **FalloffColor** in the UE4, is to make the diffusion profile narrower, and thus the width of the diffusion profile in the demo source code is reduced to 6(3x2) mm (the **RANGE** in the **calculateKernel** in the code). The default of the **falloff** in the demo source code is (1.0, 0.37, 0.3).  
3. Actually, the demo source code demonstrates that the $\displaystyle \frac{\Delta x}{0.001 + \text{falloff}}$ is passed to the diffusion profile $\displaystyle \operatorname{R}(r)$ directly without the **width** in the formula. This implies the **width** in the formula is actually fixed at 1.
4. According to the **numerical quadrature**, the function value sampled from the irradiance texture should be multiplied by the difference of the domain the $\displaystyle \operatorname{\Delta} x$ and the $\displaystyle \operatorname{\Delta} y$ (the **area** in the **calculateKernel** in the code). And the demo source code demonstrates that the deviations of the locations of the samples in world space (in mm) is fixed and stored in the **w** component of the **kernel** member of the **SeparableSSS** class. Thus, the mere purpose of the **SSSSBlurPS** in the shader code is to transform the deviations from world space to texture space. Assuming that the deviations are from the origin of the Y axis, the transformation can be calculated as $\displaystyle \text{TextureSpace} =  \frac{1}{2} \times\frac{1}{\tan(\text{FOVY} \times 0.5)} \times \frac{1}{\text{ViewPositionZInWorldSpaceUnit}} \times \frac{1}{1000 \times \text{MetersPerWorldSpaceUnit}} \times \text{WorldSpaceDeltaXInMM}$ where the 1000 is to transform from mm to m, the $\displaystyle \frac{1}{\tan(\text{FOVY} \times 0.5)}$ is the second row and the second column of the projection matrix, and the 2 is to transform from NDC to texture space. However, since the width of the diffusion profile is fixed at 6(3x2) mm and the $\displaystyle \frac{\Delta x}{0.001 + \text{falloff}}$ is passed to the diffusion profile $\displaystyle \operatorname{P}(r)$ directly without the $\displaystyle w$ in the formula, the **sssWidth**, which is **ScatterRadius** in the UE4, is impossible to be considered as the **width** of the diffusion profile or the **width** in the formula. And since the shader code of the demo source code demonstrates that the transformation is calculated as $\displaystyle \text{TextureSpace} = \frac{1}{\tan(\text{FOVY} \times 0.5)} \times \frac{1}{\text{ViewPositionZInWorldSpaceUnit}} \times\frac{\text{sssWidth}}{3} \times \text{WorldSpaceDeltaXInMM}$, by comparing these two formulas, a hypothesis can be proposed that $\displaystyle \text{MetersPerWorldSpaceUnit} = \frac{3}{1000 \times 2 \times \text{sssWidth}}$. The default of the **sssWidth** in the demo source code is 0.012, and thus the hypothesis implies that the **MetersPerWorldSpaceUnit** of the demo is $\displaystyle \frac{1}{8}$. Actually, I check the vertex data of the head mesh in the demo, and fortunately, I find the vertex data is consistent with this result.  
5. The **SSSS_STRENGTH_SOURCE** in the shader code has nothing to do with the **strength** in the paper at all. In the demo source code, the **SSSS_STREGTH_SOURCE** is the alpha channel of the albedo texture, and is used to skip the pixels which represent the eyebrow rather than the skin. However, this empirical **strength** value is adopted by both UE4 and Unity3D. The equivalent in UE4 is called [Opacity Map](https://docs.unrealengine.com/4.26/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/#materialinputchannels), and the equivalent in Unity3D is called [Subsurface Mask Map](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Material-Type.html).  

Canonically, we should **NOT** blur the specular lighting. Thus, a dedicated [specularRT](https://github.com/iryoku/separable-sss/blob/master/Demo/Shaders/Main.fx#L272) is added in the demo source code provided by \[Jimenez 2015\] to store the specular lighting. However, the [checkerboard rendering](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/LightAccumulator.ush#L18), which is a bit tricky, is applied in UE4 to store the diffuse lighting and specular lighting in adjacent pixels. And the gbuffer data is modified by [AdjustBaseColorAndSpecularColorForSubsurfaceProfileLighting](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/DeferredShadingCommon.ush#L605) in UE4 before the lighting is calculated.  
   
## 1-4\. Disney SSS
The **diffuse reflectance** term of [Unity3D](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html) and the **Subsurface Profile** [Shading Model](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/MaterialProperties/LightingModels/) with [Enable Burley](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/) of UE4 is based on the **Disney SSS** \[Golubev 2018\].  

The diffusion profile $\displaystyle \operatorname{R}(r) = \frac{A s}{8 \pi r}(e^{-sr}+e^{-\frac{1}{3}sr})$, where the A is the surface albedo and the s is the scaling factor, proposed by \[Christensen 2015\] is applied.  


#### 1-4-1\. Monte Carlo Integration  

##### 1-4-1-1\. PDF
Analogously to "Figure 13.10" of [PBR Book](https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/2D_Sampling_with_Multidimensional_Transformations#SamplingaUnitDisk), we have $\displaystyle \int_{-\infin}^\infin \int_{-\infin}^\infin \operatorname{R}({\Delta x}, {\Delta y}) \, d {\Delta x} d {\Delta y}  = \int_0^\infin \int_0^{2\pi} \operatorname{R}(r) r \, d \theta dr = \int_o^\infin \operatorname{R} (r) 2 \pi r \, dr$. And by \[Christensen 2015\], we have $\displaystyle \int_o^\infin \operatorname{R} (r) 2 \pi r \, dr = A$. The result is exactly the surface albedo A. And actually, by "Equation \(11.11\)" of [PBR Book](https://pbr-book.org/3ed-2018/Volume_Scattering/The_BSSRDF#eq:bssrdf-effective-albedo), the surface albedo A can also be called the effective albedo $\displaystyle {\rho}_{eff}$. Evidently, by \[Golubev 2018\], the normalized function $\displaystyle \operatorname{p}(r, \theta) = \frac{\operatorname{R}(r)}{A} r = \frac{s}{8 \pi}(e^{-sr}+e^{-\frac{sr}{3}})$ is used as the PDF .  

##### 1-4-1-2\. Sampling Diffusion Profile  

Analogously to "Equation \(14.1\)" of [PBR Book](https://pbr-book.org/3ed-2018/Light_Transport_I_Surface_Reflection/Sampling_Reflection_Functions#MicrofacetBxDFs), we can derive the sampling of diffusion profile. Since the diffusion profile is isotropic (radially symmetric), we have $\displaystyle \displaystyle \operatorname{p}(\theta | r) = \frac{1}{2 \pi} \Rightarrow \theta = 2 \pi \xi_2$. Since the PDF is $\displaystyle \operatorname{p}(r, \theta) = \frac{\operatorname{R}(r)}{A} r$, we have the marginal PDF $\displaystyle \operatorname{p}(r) = \int_0^{2 \pi} \operatorname{R}(r) \, d \theta = \operatorname{R}(r) 2 \pi r$ and the CDF $\displaystyle \operatorname{P}(r) = \int_0^{r} \operatorname{p}(r') \, d r' = \xi_1$. Fortunately, by \[Golubev 2018\], the inverse of the CDF is closed-form and we have $\displaystyle r = \frac{1}{s} \cdot 3 \cdot \log_2(\frac{1 + {\operatorname{G}(u)}^{-\frac{1}{3}} + {\operatorname{G}(u)}^{\frac{1}{3}}}{4 u})$ where $\displaystyle \operatorname{G}(u) = 1 + 4u(2u + \sqrt{1 + 4u^2})$ and $\displaystyle u = 1 - \xi_1$.  

The sampling of diffusion profile is calculated by [RadiusRootFindAnalytic](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/SubsurfaceBurleyNormalized.ush#L347) in UE4 and [SampleBurleyDiffusionProfile](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.compute#L182) in Unity3D.  

##### 1-4-1-3\. Pseudo-Random Sequence  

The $\displaystyle \xi_1$ is generated by pseudo-random sequence in UE4 and by evenly spaced sequence in Unity3D.  

The **pseudo-random sequence** is calculated by [Generate2DRandomNumber](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/SubsurfaceBurleyNormalized.ush#L935) in UE4 and the **evenly spaced sequence** is calculated by [i * scale + offset](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.compute#L182) in Unity3D.  

And the $\displaystyle \xi_2$ is generated by **Fibonacci sequence**, which is related to the [Golden Ratio](https://en.wikipedia.org/wiki/Golden_ratio#Relationship_to_Fibonacci_sequence), in both UE4 and Unity3D.  

The **Fibonacci sequence** is calculated by [FIBONACCI_SEQUENCE_ANGLE](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/SubsurfaceBurleyNormalized.ush#L332) in UE4 and [Fibonacci2d](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.core/ShaderLibrary/Sampling/Fibonacci.hlsl#L248) in Unity3D.  

##### 1-4-1-4\. Low-Discrepancy Sequence  

By "20.3 Quasirandom Low-Discrepancy Sequences" of \[Colbert 2007\] and "13.8.2 Quasi Monte Carlo" of [PBR Book](https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/Careful_Sample_Placement#QuasiMonteCarlo), the **low-discrepancy sequence** is the better alternative than **pseudo-random sequence** to generate the $\displaystyle \xi_1$ and $\displaystyle \xi_2$.  

For example, the **Hammersley sequence** ("7.4.1 Hammersley and Halton Sequences" of [PBR Book](https://pbr-book.org/3ed-2018/Sampling_and_Reconstruction/The_Halton_Sampler#HammersleyandHaltonSequences)) is a typical **low-discrepancy sequence**.  

The **Hammersley sequence** is calculated by [Hammersley](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/MonteCarlo.ush#L34) in UE4 and [Hammersley2d](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.core/ShaderLibrary/Sampling/Hammersley.hlsl#L415) in Unity3D.  

##### 1-4-1-5\. Stratified Sampling

In UE4, the **Center Sample Reweighting**, which is controlled by the macro **REWEIGHT_CENTER_SAMPLE**, is used, and the **CDF** of the center sample is calculated and removed from the vicinal samples. And UE4 claims that the result of this approach is still unbiased.  

#### 1-4-2\. Albedo  

By appealing $\displaystyle \operatorname{p}(r, \theta) = \frac{\operatorname{R}(r)}{A} r$ to $\displaystyle \operatorname{L_v}(p_o) = \int_{{\reals}^2} \operatorname{R}(p - p_o) \cdot \operatorname{F}(p) \, dp$, we have $\displaystyle \operatorname{L_v}(p_o) = \int_{{\reals}^2} \operatorname{R}(p - p_o) \cdot \operatorname{F}(p) \, dp = \int_{-\infin}^\infin \int_{-\infin}^\infin \operatorname{R}({\Delta x}, {\Delta y}) \cdot \operatorname{F}(p) \, d {\Delta x} d {\Delta y} = \int_0^\infin \int_0^{2\pi} \operatorname{R}(r) r \cdot \operatorname{F}(p) \, d \theta dr = \int_0^\infin \int_0^{2\pi} \frac{A \cdot \operatorname{p}(r, \theta)}{r} \cdot r \cdot \operatorname{F}(p) \, d \theta dr = \int_0^\infin \int_0^{2\pi} A \cdot \operatorname{p}(r, \theta) \cdot \operatorname{F}(p) \, d \theta dr$.  

And by "Equation \(13.3\)" of [PBR Book](https://pbr-book.org/3ed-2018/Monte_Carlo_Integration/The_Monte_Carlo_Estimator), we have the **Monte Carlo estimator** $\displaystyle \operatorname{L_v}(p_o) = \int_0^\infin \int_0^{2\pi} A \cdot \operatorname{p}(r, \theta) \cdot \operatorname{F}(p) \, d \theta dr = \sum \frac{1}{N} \frac{A \cdot \operatorname{p}(r, \theta) \cdot \operatorname{F}(p)}{\operatorname{p^i}(r, \theta)}$.  

Technically, $\displaystyle \operatorname{R}(r)$ is spectrally varying. This means that the $\displaystyle \operatorname{p}(r, \theta) = \frac{\operatorname{R}(r)}{A} r$ is a vector "RGB". However, the PDF, which is used to calculate the sampling of the diffusion profile, should be a scalar "float". Thus, the spectral channel i is selected as the PDF and we have $\displaystyle \operatorname{p^i}(r, \theta) = \frac{\operatorname{R^i}(r)}{A} r$. This means that the $\displaystyle \operatorname{p}(r, \theta)$ in the numerator is a vector "RGB" while the $\displaystyle \operatorname{p^i}(r, \theta)$ in the denominator is a scalar "float". Analogously to the "Equation 15.11" of [PBR Book](https://pbr-book.org/3ed-2018/Light_Transport_II_Volume_Rendering/Sampling_Volume_Scattering#eq:homogeneous-medium-pmed), the average over all spectral channels can be used as the PDF. However, in real time rendering, the spectral channel corresponding to the minimum PDF is usually used for efficiency.  

However, the A depends on the position. This means that the formula should be technically written as $\displaystyle \operatorname{L_v}(p_o) = \int_0^\infin \int_0^{2\pi} A \cdot \operatorname{p}(r, \theta) \cdot \operatorname{F}(p) \, d \theta dr = \int_0^\infin \int_0^{2\pi} \operatorname{A}(p) \cdot \operatorname{p}(r, \theta) \cdot \operatorname{F}(p) \, d \theta dr$.  

The **Post-Scatter** **Texturing Mode** assumes that the $\displaystyle \operatorname{A}(p)$ of each vicinal location equals the constant $\displaystyle   \operatorname{A}(p_o)$ of the center, and thus we have $\displaystyle \operatorname{L_v}(p_o) = \sum \frac{1}{N} \frac{\operatorname{A}(p_o) \cdot \operatorname{p}(r, \theta) \cdot \operatorname{F}(p)}{\operatorname{p}(r, \theta)}$ where the A is applied after the blur pass.  

The **Pre- and Post-Scatter** **Texturing Mode** assumes that the "square root" $\displaystyle \sqrt{\operatorname{A}(p)}$ of each vicinal location equals the constant $\displaystyle \sqrt{\operatorname{A}(p_o)}$ of the center, and thus we have $\displaystyle \operatorname{L_v}(p_o) = \sum \frac{1}{N} \frac{\sqrt{\operatorname{A}(p_o)} \cdot \operatorname{p}(r, \theta) \cdot \sqrt{\operatorname{A}(p)} \cdot \operatorname{F}(p)}{\operatorname{p}(r, \theta)}$ where the albedo is applied before and after the blur pass.  

Both **Post-Scatter** and **Pre- and Post-Scatter** [Texturing Mode](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html)s are supported in Unity3D. However, only the **Post-Scatter** **Texturing Mode** is supported in UE4.  

The **Texturing Mode** is controlled by [GetModifiedDiffuseColorForSSS](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/Lit/Lit.hlsl#L2023) and [ApplySubsurfaceScatteringTexturingMode](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/Material/SubsurfaceScattering/SubsurfaceScattering.compute#L395) in Unity3D, and [AdjustBaseColorAndSpecularColorForSubsurfaceProfileLighting](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/DeferredShadingCommon.ush#L605) and [SubsurfaceRecombinePS](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Shaders/Private/PostProcessSubsurface.usf#L741) in UE4.  

#### 1-4-3\. Bilateral Filter  

The approach of \[Mikkelsen 2010\] is used by \[Golubev 2018\] to the estimated surface area based on the screen space area.  

We assume that x is the point on the surface, and p is the perspective projection of x on the screen space. Let $\displaystyle \operatorname{{\Delta x}_{xy}} = \sqrt{{(x.x - x_o.x)}^2 + {(x.y - x_o.y)}^2}$ and $\displaystyle {\Delta x}_z = |x.z - x_o.z|$. We have $\displaystyle \|x - x_o\| = \sqrt{{{\Delta x}_{xy}}^2 + {{\Delta x}_z}^2}$ and $\displaystyle \operatorname{{\Delta x}_{xy}}$ can be approximated by $\displaystyle K_{p_o} \cdot \|p - p_o\|$ where $\displaystyle K_{p_o} = \frac{2 \cdot r_{max} \cdot |\cos \theta_o|}{d \cdot \cos \phi_o}$. The form of this equation may remind us of the one degree [Taylor polynomial](https://en.wikipedia.org/wiki/Taylor%27s_theorem), but $\displaystyle r_{max}$ and $\displaystyle d$ are the macro quantities which can **NOT** be explained by the micro differential.  

By \[Mikkelsen 2010\], the $\displaystyle K_{p_o}$ does **NOT** need to be calculated when the diffusion profile $\displaystyle \operatorname{R}(x)$ is the Gaussian function $\displaystyle \operatorname{G}(\sigma, x)$. However, the diffusion profile $\displaystyle \operatorname{R}(x)$ of \[Golubev 2018\] is **NOT** the Gaussian function, and thus the formula provided by \[Mikkelsen 2010\] does **NOT** apply. The Unity3D and the UE4 both merely assume that $\displaystyle K_{p_o} = 1$, and the $\displaystyle \|x - x_o\|$ can be estimated as $\sqrt{{\|p - p_o\|}^2 + {{\Delta x}_z}^2}$.  

The **Bilateral Filter** is controlled by the macro **SSS_BILATERAL_FILTER** in the Unity3D and the macro **USE_BILATERAL_FILTERING** in the UE4.  

#### 1-4-4\. Properties between Unity3D and UE4  
Formula Name | [Unity3D Name](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html) | [Unity3D Default](https://github.com/Unity-Technologies/Graphics/blob/v10.8.0/com.unity.render-pipelines.high-definition/Runtime/RenderPipelineResources/Skin%20Diffusion%20Profile.asset#L17) | [UE4 Name](https://docs.unrealengine.com/4.27/en-US/RenderingAndGraphics/Materials/LightingModels/SubSurfaceProfile/) | [UE4 Default](https://github.com/EpicGames/UnrealEngine/blob/4.27/Engine/Source/Runtime/Engine/Classes/Engine/SubsurfaceProfile.h#L113)  
:-: | :-: | :-: | :-: | :-:  
A | Diffuse Color | N/A | Base Color | N/A  
N/A | N/A | N/A | Surface Albedo | (0.91058, 0.338275, 0.2718)  
N/A | N/A | N/A | Mean Free Path Color | (1.0, 0.1983/2.229, (0.1607/2.229)  
N/A | N/A | N/A | Mean Free Path Distance | (1.2\*2.229, 1.2\*2.229, 1.2\*2.229)  
N/A | Scattering Distance | (0.7568628, 0.32156864, 0.20000002) | N/A | N/A  
s | N/A | $\displaystyle \frac{1}{\mathrm{ScatteringDistance}}$ | N/A | $\displaystyle \frac{\operatorname{GetScalingFactor}(\mathrm{SurfaceAlbedo})}{\mathrm{MeanFreePathColor} \cdot \mathrm{MeanFreePathDistance}}$  
N/A | Texturing Mode | Pre- and Post-Scatter | N/A |  Post-Scatter  
N/A | World Scale | 1 (Meters Per Unit) | World Unit Scale | 0.1 (Units Per Centimeter)  

Note that, in UE4, the scaling factor is calculated by $\displaystyle s = \frac{\operatorname{GetScalingFactor}(\mathrm{SurfaceAlbedo})}{\mathrm{MeanFreePathColor} \cdot \mathrm{MeanFreePathDistance}}$ where the $\displaystyle \operatorname{GetScalingFactor}$ follows the Equation 5, 6, 7 of \[Christensen 2015\]. But, by \[Christensen 2015\], the result of the $\displaystyle \operatorname{GetScalingFactor}$ is exactly the scaling factor. Thus, the denominator is **NOT** reasonable.  

### 1-5\. Disney Diffuse
TODO  

## 2\. Diffuse Transmittance Term

### 2-1\. Deep Scatter
The **diffuse transmittance** term of the FaceWorks is based on the **16.3 Simulating Absorption Using Depth Maps** of \[Green 2004\].  

The main idea of \[Green 2004\] is that the objects are assumed to be convex, and thus the thickness (the distance a light ray travels inside an object) can be estimated by using the shadow maps. According to the thickness, the [Beer–Lambert law](https://en.wikipedia.org/wiki/Beer%E2%80%93Lambert_law) can be applied to calculate the transmittance coefficient.  

In the FaceWorks, the **thickness** is calculated by **GFSDK_FaceWorks_EstimateThicknessFromParallelShadowPoisson32** and the **transmittance coefficient** is calculated by **GFSDK_FaceWorks_EvaluateDeepScatterDirectLight**.  

### 2-2\. Analytically-Integrated Translucency  
The **diffuse transmittance** term of demo source code provided by \[Jimenez 2015\] is based on \[Jimenez 2010\].  

The main idea of \[Jimenez 2010\] is that the approach proposed by \[Green 2004\] is applied to calculate the thickness while the transmittance coefficient is calculated based on the diffusion profile rather than the **Beer–Lambert law**. According to \[Jimenez 2010\], the idea of the **14.5.3 Modified Translucent Shadow Maps** of \[dEon 2007\] is applied, and the transmittance coefficient is calculated as $\displaystyle \operatorname{T}(d) = \int_o^\infin 2 \pi r \cdot \operatorname{R} (\sqrt{r^2 + d^2}) \, dr$ where the R is the 1D diffusion profile and the r is the distance over the surface. If the diffusion profile is approximated by the Gaussians proposed by \[Green 2004\], the result of the integral is analytical and can be calculated as $\displaystyle \operatorname{T}(d) = \sum_i^k w_i e^{\frac{-d^2}{v_i}}$.  

The **transmittance coefficient** is calculated by the **SSSSTransmittance** in the demo source code provided by \[Jimenez 2015\]. And there are some points to note.  
1. The demo uses **0.005** to shrink the object in the normal direction to avoid artifacts. Evidently, this value is proportional to the $\displaystyle \frac{1}{\text{MetersPerWorldSpaceUnit}}$.  
2. Actually, the mere purpose of the **scale** in the shader code is to transform the thickness from world space unit to mm. The shader code of the demo source code demonstrates that the **scale** is calculated as $\displaystyle 8.25 \times (1 - \text{translucency}) \times \frac{1}{\text{sssWidth}}$. According to the **1-3\. Separable SSS** of this page, the $\displaystyle \frac{1}{\text{sssWidth}}$ can be substituted as $\displaystyle \frac{1000 \times 2 \times \text{MetersPerWorldSpaceUnit}}{3}$, and thus the **scale** is actually calculated as $\displaystyle 8.25 \times (1 - \text{translucency}) \times \frac{2}{3} \times 1000 \times \text{MetersPerWorldSpaceUnit}$. The default of the **translucency** in the demo source code is 0.83, and thus the value of $\displaystyle 8.25 \times (1 - \text{translucency}) \times \frac{2}{3}$ is 0.935 which is really close to 1. This implies that the **scale** is actually calculated as $\displaystyle 1000 \times \text{MetersPerWorldSpaceUnit}$ which is exactly the transformation from world space unit to mm.  

### 2-3\. Baked Textured Thickness  
The **diffuse transmittance** term of Unity3D is based on \[Golubev 2018\].  

\[Golubev 2018\] follows the analytically-integrated formula of \[Jimenez 2010\] while the diffuse profile of \[Christensen 2015\] is applied. And thus, we have that $\displaystyle \operatorname{T}(d) = \int_o^\infin 2 \pi r \cdot \operatorname{R} (\sqrt{r^2 + d^2}) \, dr = \frac{1}{4} A (e^{-sd} + 3e^{-\frac{sd}{3}})$.  

There are two [Transmission Mode](https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@10.8/manual/Diffusion-Profile.html)s in Unity3D: **Thick Object** and **Thin Object**. The **Thick Object** mode merely follows the approach of \[Jimenez 2010\] which uses the shadow map to calculate the thickness. And the **Thin Object** mode uses the baked textured thickness which can be provided by the [Substance](https://substance3d.adobe.com/documentation/bake/thickness-map-from-mesh-172818642.html).  

In the [Unity3D](https://github.com/Unity-Technologies/Graphics), the **thickness** is calculated by the **FillMaterialTransmission**, the **ShouldEvaluateThickObjectTransmission** and the **EvaluateTransmittance_Punctual**.  


## 3\. Specular Term  

### 3-1\. Two-lobe Blinn-Phong  
TODO  
  
### 3-2\. Dual GGX    
TODO  

## References
\[Kelemen 2001\] [Csaba Kelemen, László Szirmay-Kalos. "A Microfacet Based Coupled Specular-Matte BRDF Model with Importance Sampling." EGSR 2001.](http://cg.iit.bme.hu/~szirmay/scook_link.htm)  
\[Green 2004\] [Simon Green. "Chapter 16. Real-Time Approximations to Subsurface Scattering." GPU Gems 1.](https://developer.nvidia.com/gpugems/gpugems/part-iii-materials/chapter-16-real-time-approximations-subsurface-scattering)  
\[dEon 2007\] [Eugene dEon, David Luebke. "Advanced Techniques for Realistic Real-Time Skin Rendering." GPU Gem 3.](https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-14-advanced-techniques-realistic-real-time-skin)  
\[Colbert 2007\] [Mark Colbert, Jaroslav Krivanek. "GPU-Based Importance Sampling." GPU Gems 3.](https://developer.nvidia.com/gpugems/gpugems3/part-iii-rendering/chapter-20-gpu-based-importance-sampling)  
\[Jimenez 2009\] [Jorge Jimenez, Veronica Sundstedt, Diego Gutierrez. "Screen-Space Perceptual Rendering of Human Skin." ACM TAP 2009.](https://www.iryoku.com/sssss/)  
\[Jimenez 2009\] Jorge Jimenez, Diego Gutierrez. "Screen-Space Subsurface Scattering." GPU Pro 1.  
\[Jimenez 2010\] [Jorge Jimenez, David Whelan, Veronica Sundstedt, Diego Gutierrez. "Real-Time Realistic Skin Translucency." IEEE 2010.](http://www.iryoku.com/translucency/)  
\[Mikkelsen 2010\] [Morten Mikkelsen. "Skin Rendering by Pseudo–Separable Cross Bilateral Filtering." Naughty Dog.](https://mmikk.github.io/papers3d/cbf_skin.pdf)  
\[Penner 2011\] Eric Penner, George Borshukov. "Pre-Integrated Skin Shading." GPU Pro 2.  
\[Penner 2011\] [Eric Penner. "Pre-Integrated Skin Shading." SIGGRAPH 2011.](http://advances.realtimerendering.com/s2011/)  
\[Lazarov 2011\] [Dimitar Lazarov. "Physically Based Lighting in Call of Duty : Black Ops." SIGGRAPH 2011.](http://advances.realtimerendering.com/s2011/)  
\[Jimenez 2012\] [Jorge Jimenez, Adrian Jarabo, Diego Gutierrez. "Separable Subsurface Scattering." Technical Report 2012.](https://graphics.unizar.es/publications.html#year_2012)   
\[Jimenez 2012\] [Jorge Jimenez, Adrian Jarabo, Diego Gutierrez, Etienne Danvoye, Javier von der Pahlen. "Separable Subsurface Scattering and Photorealistic Eyes Rendering." SIGGRAPH 2012.](http://advances.realtimerendering.com/s2012/index.html)  
\[Jimenez 2015\] [Jorge Jimenez, Karoly Zsolnai, Adrian Jarabo1, Christian Freude, Thomas Auzinger, Xian-Chun Wu, Javier von der Pahlen, Michael Wimmer, Diego Gutierrez. "Separable Subsurface Scattering." EGSR 2015.](http://www.iryoku.com/separable-sss/)  
\[Christensen 2015\] [Per Christensen, Brent Burley. "Approximate Reflectance Profiles for Efficient Subsurface Scattering." SIGGRAPH 2015.](https://graphics.pixar.com/library/)  
\[Golubev 2018\] [Evgenii Golubev. "Efficient Screen-Space Subsurface Scattering Using Burley's Normalized Diffusion in Real-Time." SIGGRAPH 2018.](https://zero-radiance.github.io/post/sampling-diffusion/)  
