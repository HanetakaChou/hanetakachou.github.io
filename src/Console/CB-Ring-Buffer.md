# CB(Command Buffer) Ring Buffer  

## Vulkan

In Vulkan, the memory of the command buffer is managed by the driver. Usually, the application allocates \"frame\_[throttling](https://community.arm.com/arm-community-blogs/b/graphics-gaming-and-vr-blog/posts/the-mali-gpu-an-abstract-machine-part-1---frame-pipelining)\_count\" command pools in advance, and uses the "frame_throttling_index" to select the command pool from which the command buffers are allocated in each frame. Note that the "frame_throttling_count" should be distinguished from the "swapchain_image_count".  

For example, in [RADV](https://docs.mesa3d.org/drivers/radv.html), the memory is stored in the list [radv_amdgpu_cs::handles](https://gitlab.freedesktop.org/mesa/mesa/-/blob/22.3/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c#L482). Evidently, we can NOT know in advance how much memory we should allocate for the command buffer at the begining of each frame. Hence, when we are out of memory, we need to allocate a new buffer object and insert the new buffer object to the list (see [cs_grow](https://gitlab.freedesktop.org/mesa/mesa/-/blob/22.3/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c#L409), [radv_cmd_buffer_resize_upload_buf](https://gitlab.freedesktop.org/mesa/mesa/-/blob/22.3/src/amd/vulkan/radv_cmd_buffer.c#L546) and [cs_add_buffer](https://gitlab.freedesktop.org/mesa/mesa/-/blob/22.3/src/amd/vulkan/winsys/amdgpu/radv_amdgpu_cs.c#L547) for more information). Thus, the memory of the command buffer is NOT continuous, and is composed by several buffer objects in the list.  

Peculiarly, the RADV follows the Mesa3D [common command pool framework](https://gitlab.freedesktop.org/mesa/mesa/-/blob/22.3/src/vulkan/runtime/vk_command_pool.c#L131) where the vkResetCommandPool is implemented by the vkResetCommandBuffer. This means that the memory of the command buffer is managed by the command buffer rather than the command pool in RADV.  

## Console  

In console, the memory of the command buffer is managed by the application rather than the driver. When the command buffer is initialized by the application, a memory buffer can be provided by the application. And when the command buffer is out of the memory, the callback provided by the application is invoked to request another memory buffer.  

Evidently, it may be too difficult for the application to manage the memory of the command buffer. Thus, the ring buffer is provided by the SDK to help the application to manage the memory. The out-of-memory callback of the command buffer can be provided by the ring buffer.  
 
The "memory buffer object" is called the "segment" by the ring buffer. When the ring buffer is initialized by the application, several segments are provided by the application. The ring buffer inserts the "jump" packets to connect the separated segments. And when there is no remaining segment, the ring buffer will wait for the GPU by default.  

Evidently, it is the most efficient strategy to use only one segment for each command buffer in each frame, since the "jump" packets can be skipped, and it is NOT efficient to wait for the GPU. In my view, the implementation of the ring buffer is similar to the [Direct3D11 Constant Buffer](https://developer.nvidia.com/content/constant-buffers-without-constant-pain-0), which is NOT the optimal, where the application will wait for the GPU and stall when the memory of the constant buffer is run out. To improve the performance, the memory of the constant buffer is visible to the application in Vulkan. And the ring buffer is usually used by the application (see [Fence-Based Resource Management](https://learn.microsoft.com/en-us/windows/win32/direct3d12/fence-based-resource-management#ring-buffer-scenario) and [Dynamic Uniform buffers](https://github.com/KhronosGroup/Vulkan-Samples/tree/main/samples/api/dynamic_uniform_buffers) for more information) to manage the memory of the constant buffer. But the application never waits for the GPU, but instead skips the objects which exceed the memory of the constant buffer in the current frame, and tries to allocate more memory for the constant buffer in the next frame.  

In my view, perhaps we should NOT use the ring buffer in the product, since the implementation of the ring buffer is NOT the optimal. The more important point than the ring buffer is that since the memory of the command buffer is visible to the application, the most efficient strategy, which may be NOT compatible with the mainstream API specifications such as Vulkan or Direct3D, can be adopted by the application. For example, only one segment is used for each command buffer in each frame to skip the "jump" packets, and the strategy which is used to manage the memory of constant buffer in Vulkan can be adopted. The application never waits for the GPU, but instead stops recording and submits the command buffer when the memory of the command buffer is run out in the current frame, and tries to allocate more memory for the command buffer in the next frame.  
